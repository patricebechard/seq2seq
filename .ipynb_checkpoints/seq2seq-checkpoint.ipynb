{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 30\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DATADIR = 'data/'\n",
    "\n",
    "word2ix_src_file = 'word2ix_en_filtered.json'\n",
    "ix2word_src_file = 'ix2word_en_filtered.json'\n",
    "word2ix_tgt_file = 'word2ix_fr_filtered.json'\n",
    "ix2word_tgt_file = 'ix2word_fr_filtered.json'\n",
    "\n",
    "pairs_file = 'pairs_en_fr_filtered.json'\n",
    "\n",
    "with open(DATADIR + word2ix_src_file) as f:\n",
    "    word2ix_src = json.load(f)\n",
    "with open(DATADIR + ix2word_src_file) as f:\n",
    "    ix2word_src = json.load(f)\n",
    "with open(DATADIR + word2ix_tgt_file) as f:\n",
    "    word2ix_tgt = json.load(f)\n",
    "with open(DATADIR + ix2word_tgt_file) as f:\n",
    "    ix2word_tgt = json.load(f)\n",
    "\n",
    "with open(DATADIR + pairs_file) as f:\n",
    "    pairs = json.load(f)\n",
    "    \n",
    "source_vocab_size = len(word2ix_src)\n",
    "target_vocab_size = len(word2ix_tgt)\n",
    "\n",
    "n_pairs = len(pairs)\n",
    "np.random.shuffle(pairs)\n",
    "\n",
    "#split into three subsets (train, dev, test)\n",
    "train_pairs = pairs[:(9 * n_pairs// 10)] #90%\n",
    "dev_pairs = pairs[(9 * n_pairs // 10):(19 * n_pairs // 20)] #5%\n",
    "test_pairs = pairs[(19 * n_pairs // 20):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs_batch(update_num, mode='train'):\n",
    "    #0 is UNK, 1 is BOS, 2 is EOS, 3 is PAD\n",
    "    #bos is only used in target_in\n",
    "    # i is # of update\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = train_pairs\n",
    "    elif mode == 'dev':\n",
    "        dataset = dev_pairs\n",
    "    elif mode == 'test':\n",
    "        dataset = test_pairs\n",
    "        \n",
    "    num_pairs = len(dataset)\n",
    "    \n",
    "    index = (update_num * batch_size) % num_pairs\n",
    "    inputs_batch = []\n",
    "    targets_in_batch = []\n",
    "    targets_out_batch = []\n",
    "\n",
    "    max_src_len = 0\n",
    "    max_tgt_len = 0\n",
    "    for j in range(batch_size):\n",
    "        pair = pairs[(index + j) % num_pairs]   #modulo used so that we are always in the index range\n",
    "        \n",
    "        inputs = pair['source']\n",
    "        targets_in = pair['target']\n",
    "        targets_out = pair['target']\n",
    "        \n",
    "        # add <BOS> and <EOS> tokens\n",
    "        inputs = inputs + [int(word2ix_src['<EOS>'])]\n",
    "        targets_in = [int(word2ix_tgt['<BOS>'])] + targets_in\n",
    "        targets_out = targets_out + [int(word2ix_tgt['<EOS>'])]\n",
    "        \n",
    "        if len(inputs) > max_src_len:\n",
    "            max_src_len = len(inputs)\n",
    "        if len(targets_out) > max_tgt_len:\n",
    "            max_tgt_len = len(targets_out)\n",
    "        \n",
    "        # adding to batch\n",
    "        inputs_batch.append(inputs)\n",
    "        targets_in_batch.append(targets_in)\n",
    "        targets_out_batch.append(targets_out)\n",
    "    \n",
    "    #padding sequences to same length\n",
    "    for j in range(batch_size):\n",
    "        \n",
    "        tmp = len(inputs_batch[j])\n",
    "        inputs_batch[j] = inputs_batch[j] + (max_src_len - tmp) * [int(word2ix_src['<PAD>'])]\n",
    "        \n",
    "        tmp = len(targets_out_batch[j])\n",
    "        targets_in_batch[j] = targets_in_batch[j] + (max_tgt_len - tmp) * [int(word2ix_src['<PAD>'])]\n",
    "        targets_out_batch[j] = targets_out_batch[j] + (max_tgt_len - tmp) * [int(word2ix_src['<PAD>'])]\n",
    "        \n",
    "    \n",
    "    inputs_batch = torch.LongTensor(inputs_batch).t()\n",
    "    targets_in_batch = torch.LongTensor(targets_in_batch).t()\n",
    "    targets_out_batch = torch.LongTensor(targets_out_batch).t()\n",
    "    \n",
    "    return inputs_batch, targets_in_batch, targets_out_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, source_vocab_size, target_vocab_size, embedding_size=256, hidden_size=256,\n",
    "                 attention_size=256, num_layers=1, max_seq_len=30):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        \n",
    "        self.encoder = Encoder(input_size=source_vocab_size, \n",
    "                               embedding_size=embedding_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               num_layers=num_layers)\n",
    "        \n",
    "        self.decoder = Decoder(output_size=target_vocab_size,\n",
    "                               embedding_size=embedding_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               attention_size=attention_size,\n",
    "                               num_layers=num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_size=256, hidden_size=256,\n",
    "                 num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden0 = nn.Parameter(torch.zeros(2*num_layers, 1, hidden_size//2))\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n",
    "        self.encoder_rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size//2, \n",
    "                                  num_layers=num_layers, bidirectional=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self._init_hidden()\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.encoder_rnn(x, hidden)\n",
    "\n",
    "        return x, hidden\n",
    "\n",
    "    def _init_hidden(self):\n",
    "        # initial hidden state is a learned bias parameter\n",
    "        hidden = self.hidden0.clone().repeat(1, batch_size, 1)\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_size, embedding_size=256, hidden_size=256,\n",
    "                 attention_size=256, num_layers=1):\n",
    "        \"\"\"\n",
    "        We use the original attention mechanism from Bahdanau et al. 2014\n",
    "        The layers are of this model correspond to the following notation in the original paper.\n",
    "        \n",
    "        attn_fc_prev_hid : Wa\n",
    "        attn_fc_enc_hid : Ua\n",
    "        attn_fc_context : va\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "        # attention\n",
    "        self.attn_fc_prev_hid = nn.Linear(in_features=hidden_size, \n",
    "                                          out_features=attention_size)\n",
    "        self.attn_fc_enc_hid = nn.Linear(in_features=hidden_size, \n",
    "                                         out_features=attention_size)\n",
    "        self.attn_fc_context = nn.Linear(in_features=attention_size,\n",
    "                                         out_features=1)\n",
    "    \n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)    \n",
    "        self.decoder_rnn = nn.GRU(input_size=(embedding_size + hidden_size), \n",
    "                                  hidden_size=hidden_size, \n",
    "                                  num_layers=num_layers)\n",
    "        self.clf = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, encoder_outputs):\n",
    "        \n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # attention\n",
    "        tmp1 = self.attn_fc_prev_hid(self.hidden[0])\n",
    "        tmp2 = self.attn_fc_enc_hid(encoder_outputs)\n",
    "\n",
    "        context_weights = self.attn_fc_context(F.tanh(tmp1 + tmp2))\n",
    "        context_weights = F.softmax(context_weights, 0)\n",
    "        self.attn_weights = context_weights #for attention plotting purposes\n",
    "        \n",
    "        context_weights = context_weights.permute(1, 2, 0) # (batch size x 1 x seq_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # (batch size x seq_len x 2*hidden_dim)\n",
    "\n",
    "        context_vector = torch.bmm(context_weights, encoder_outputs)\n",
    "        context_vector = context_vector.permute(1, 0, 2) # (1 x batch_size x 2*hidden_dim)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        #concatenate previously predicted word embedding and context vector\n",
    "        x = torch.cat((x, context_vector), dim=-1)\n",
    "        x, self.hidden = self.decoder_rnn(x, self.hidden)\n",
    "        x = self.clf(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_hidden(self, encoder_hidden_state):\n",
    "        \n",
    "        self.hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            self.hidden = self.hidden.cuda()\n",
    "        for layer in range(self.num_layers):\n",
    "            self.hidden[layer] = torch.cat((encoder_hidden_state[2*layer],\n",
    "                                    encoder_hidden_state[2*layer + 1]), dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_updates=10000, teacher_forcing_prob=0.8, print_every=1000, \n",
    "          learning_rate=1e-4, save_model=False, beam_size=10):\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    #PAD has no weight\n",
    "    weight_mask = torch.ones(len(word2ix_tgt))\n",
    "    weight_mask[int(word2ix_tgt['<PAD>'])] = 0\n",
    "    if use_cuda:\n",
    "        weight_mask = weight_mask.cuda()\n",
    "    criterion = nn.NLLLoss(weight=weight_mask)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_buffer = []\n",
    "    bleu_tracker = []\n",
    "    loss_tracker = []\n",
    "\n",
    "    # + 1 to show the last update\n",
    "    for update in range(n_updates + 1):\n",
    "        \n",
    "        loss = 0\n",
    "        teacher_forcing = True if np.random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, targets_in, targets_out = generate_pairs_batch(update)\n",
    "        inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "        if use_cuda:\n",
    "            inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "        \n",
    "        model.decoder._init_hidden(encoder_hidden)\n",
    "        \n",
    "        predicted_sequence = torch.zeros(len(targets_in)).long()\n",
    "        if use_cuda:\n",
    "            predicted_sequence = predicted_sequence.cuda()\n",
    "\n",
    "        if teacher_forcing:\n",
    "            for i in range(len(targets_in)):\n",
    "                output = model.decoder(targets_in[i], encoder_outputs)\n",
    "\n",
    "                loss += criterion(output.view(batch_size, -1), targets_out[i])\n",
    "\n",
    "                _, output = torch.max(output, -1)\n",
    "                output = output.view(batch_size)\n",
    "\n",
    "                predicted_sequence[i] = output.data[0]\n",
    "                \n",
    "        else:\n",
    "            # beam search\n",
    "            # feeding BOS tokens\n",
    "            output = Variable(torch.ones(batch_size).long())\n",
    "            beam_best_seq = torch.zeros(len(targets_in), batch_size, beam_size).long()\n",
    "            beam_best_scores = torch.zeros(batch_size, beam_size)\n",
    "            beam_seq_buffer = torch.zeros(len(targets_in), batch_size, beam_size*beam_size).long()\n",
    "            beam_scores_buffer = torch.zeros(batch_size, beam_size*beam_size)\n",
    "            if use_cuda:\n",
    "                output = output.cuda()\n",
    "                beam_best_seq = beam_best_seq.cuda()\n",
    "                beam_best_scores = beam_best_scores.cuda()\n",
    "                beam_seq_buffer = beam_seq_buffer.cuda()\n",
    "                beam_scores_buffer = beam_scores_buffer.cuda()\n",
    "            for i in range(len(targets_in)):\n",
    "                if i == 0:\n",
    "                    output = model.decoder(output, encoder_outputs)\n",
    "                    top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                    beam_best_scores = top_vals[0].data\n",
    "                    beam_best_seq[i] = top_ix.data\n",
    "                else:\n",
    "                    for j in range(beam_size):\n",
    "                        output = Variable(beam_best_seq[i-1,:,j])\n",
    "                        if use_cuda:\n",
    "                            output = output.cuda()\n",
    "                        output = model.decoder(output, encoder_outputs)\n",
    "                        \n",
    "                        top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                        top_vals = beam_best_scores[:,j].unsqueeze(-1) + top_vals.data\n",
    "                        \n",
    "                        #building buffers\n",
    "                        beam_scores_buffer[:,j*beam_size:(j+1)*beam_size] = top_vals\n",
    "                \n",
    "                        beam_seq_buffer[:i,:,j*beam_size:(j+1)*beam_size] = beam_best_seq[:i,:,j:j+1].repeat(1, 1, beam_size)\n",
    "                        beam_seq_buffer[i,:,j*beam_size:(j+1)*beam_size] = top_ix.data\n",
    "\n",
    "                    # keeping best beams from buffer\n",
    "                    top_vals, top_ix = torch.topk(beam_scores_buffer, beam_size)\n",
    "                    \n",
    "                    # updating best sequences and best scores\n",
    "                    beam_best_scores = top_vals\n",
    "                    \n",
    "                    \n",
    "                    for k in range(batch_size):\n",
    "                        for j in range(beam_size):\n",
    "                            ix = top_ix[k,j]\n",
    "                            beam_best_seq[:,k,j] = beam_seq_buffer[:,k,ix]\n",
    "            \n",
    "            #re-run with best sequence\n",
    "            best_prediction = beam_best_seq[:,:,0]\n",
    "            best_prediction = Variable(best_prediction)\n",
    "            output = Variable(torch.ones(batch_size)).long()\n",
    "            if use_cuda:\n",
    "                best_prediction = best_prediction.cuda()\n",
    "                output = output.cuda()\n",
    "\n",
    "            for i in range(len(targets_in)):  \n",
    "                output = model.decoder(output, encoder_outputs) \n",
    "\n",
    "                _, predicted_word = torch.max(output, -1)\n",
    "                predicted_word = predicted_word.view(batch_size)\n",
    "                predicted_sequence[i] = predicted_word.data[0]\n",
    "\n",
    "                loss += criterion(output.view(batch_size, -1), targets_out[i])\n",
    "                \n",
    "                #using the beam search prediction\n",
    "                output = best_prediction[i]\n",
    "            \n",
    "                predicted_sequence[i] = output.data[0]\n",
    "\n",
    "        loss /= len(targets_in) # length penalty\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        loss_buffer.append(loss.data[0])\n",
    "\n",
    "        if update % print_every == 0:\n",
    "            \n",
    "            inputs = inputs[:,0]\n",
    "            targets_out = targets_out[:,0]\n",
    "\n",
    "            # convert all sequence to list (easier to read)\n",
    "            inputs = [str(inputs.data[i]) for i in range(len(inputs))]\n",
    "            predicted_sequence = [str(predicted_sequence[i]) for i in range(len(predicted_sequence))]\n",
    "            targets_out = [str(targets_out.data[i]) for i in range(len(targets_out))]\n",
    "\n",
    "            # create string of sentence\n",
    "            og_sequence = ''.join(ix2word_src[elem] + ' ' for elem in inputs if ix2word_tgt[elem] != '<PAD>')\n",
    "            pred_sequence = ''.join(ix2word_tgt[elem] + ' ' for elem in predicted_sequence if ix2word_tgt[elem] != '<PAD>')\n",
    "            target_sequence = ''.join(ix2word_tgt[elem] + ' ' for elem in targets_out if ix2word_tgt[elem] != '<PAD>')\n",
    "            \n",
    "            #mean over print_every batches of loss\n",
    "            loss_tracker.append(np.mean(loss_buffer))\n",
    "            loss_buffer = []\n",
    "            \n",
    "            #score = compute_bleu_score(model, mode='dev')\n",
    "            score = 0\n",
    "            bleu_tracker.append(score)\n",
    "            \n",
    "            print(\"Update : %d ----- Loss : %.3f ----- BLEU : %.2f\\n-----------------------------\" % (update, loss_tracker[-1], bleu_tracker[-1]))\n",
    "            print(\"Original sequence  : %s\" % og_sequence)\n",
    "            print(\"Predicted sequence : %s\" % pred_sequence)\n",
    "            print(\"Target sequence    : %s\\n\" % target_sequence)\n",
    "            \n",
    "            if save_model:\n",
    "                #saving encoder and decoder separately\n",
    "                torch.save(model.encoder.state_dict(), 'seq2seq_encoder_en_fr.pt')\n",
    "                torch.save(model.decoder.state_dict(), 'seq2seq_decoder_en_fr.pt')\n",
    "                \n",
    "                #saving loss progress\n",
    "                np.savetxt('seq2seq_en_fr_loss.txt', np.array(loss_tracker))\n",
    "                np.savetxt('seq2seq_en_fr_bleu.txt', np.array(bleu_tracker))\n",
    "    \n",
    "    return loss_tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(source_vocab_size=source_vocab_size, target_vocab_size=target_vocab_size, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.load_state_dict(torch.load('seq2seq_encoder_en_fr.pt'))\n",
    "model.decoder.load_state_dict(torch.load('seq2seq_decoder_en_fr.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update : 0 ----- Loss : 2.983 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : counter terrorism instruments or policies which do not respect fundamental rights often play into the hands of the terrorists themselves . <EOS> \n",
      "Predicted sequence : les fonds de les regions de sante ou ou ne sont pas les droits fondamentaux des des bien les droit des etats . memes . <EOS> . . . . . \n",
      "Target sequence    : les instruments ou les politiques de contre terrorisme qui ne respectent pas les droits fondamentaux font tres souvent le jeu des terroristes eux memes . <EOS> \n",
      "\n",
      "Update : 1000 ----- Loss : 3.514 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : although this clause is rarely used it could well be used very soon in finland if i am well informed . <EOS> \n",
      "Predicted sequence : en ce n est qu il est difficile . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> ce ce \n",
      "Target sequence    : bien que cette clause soit rarement utilisee elle pourrait l etre tres bientot si mes informations sont bonnes dans le cas de la finlande . <EOS> \n",
      "\n",
      "Update : 2000 ----- Loss : 3.460 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : a principles based threats and safeguards approach will lead to a much more effective and robust eu regime . <EOS> \n",
      "Predicted sequence : une serie de la lutte contre une politique de l ue . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : une approche par risques et mesures de sauvegarde basee sur des principes conduira a un regime communautaire bien plus efficace et solide . <EOS> \n",
      "\n",
      "Update : 3000 ----- Loss : 3.394 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : thank you very much mr president . <EOS> \n",
      "Predicted sequence : merci beaucoup monsieur le president . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : je vous remercie monsieur le president . <EOS> \n",
      "\n",
      "Update : 4000 ----- Loss : 3.393 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we must get this through it is a really crucial point . <EOS> \n",
      "Predicted sequence : nous est la que nous devons un un est un probleme important . <EOS> . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : c est ce que nous devons imposer c est un point decisif ! <EOS> \n",
      "\n",
      "Update : 5000 ----- Loss : 3.331 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this should be achievable without infringing on the autonomy that member states have in running their own vocational education and training systems . <EOS> \n",
      "Predicted sequence : cela devrait etre mis en uvre les etats membres et d emploi . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : cela devrait etre realisable sans porter atteinte a l autonomie dont disposent les etats membres pour la gestion de leurs propres systemes d enseignement et de formation professionnels . <EOS> \n",
      "\n",
      "Update : 6000 ----- Loss : 3.282 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president commissioner ladies and gentlemen the miracle of bonn the kyoto baby learns to walk . <EOS> \n",
      "Predicted sequence : monsieur le president monsieur le nombre de l <UNK> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : monsieur le president madame la commissaire chers collegues un miracle s est produit a bonn l enfant de kyoto apprend a marcher . <EOS> \n",
      "\n",
      "Update : 7000 ----- Loss : 3.262 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : if parent and subsidiary companies simply provide groundhandling services for each other then we must seriously ask ourselves whether competition is genuinely being ensured ! <EOS> \n",
      "Predicted sequence : si les femme de peut plus les il la entreprises les peut egalement les concentrer des vie des l si nous situation nous la si a <EOS> a a ! ! \n",
      "Target sequence    : quand une societe ne sous traite qu a ses filiales on doit serieusement se poser la question de savoir si la concurrence est reellement assuree ! <EOS> \n",
      "\n",
      "Update : 8000 ----- Loss : 3.261 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i would like to thank them because we have really achieved a great deal . <EOS> \n",
      "Predicted sequence : je voudrais remercier remercier dire parce que nous avons fait beaucoup un bon travail . <EOS> . a . . . . . . . . . . . \n",
      "Target sequence    : je voudrais les en remercier parce que nous avons vraiment fait du bon travail . <EOS> \n",
      "\n",
      "Update : 9000 ----- Loss : 3.205 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : that said i would like to thank mrs saifi for her excellent report and i welcome the draft resolution . <EOS> \n",
      "Predicted sequence : je me dit je remercie a feliciter mme van pour son excellent rapport et je felicite felicite du vote de resolution . <EOS> . . . . . . . . \n",
      "Target sequence    : ceci etant dit je tiens a remercier mme saifi pour son excellent rapport et je me felicite du projet de resolution . <EOS> \n",
      "\n",
      "Update : 10000 ----- Loss : 3.217 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we should spend money on offshore projects in the north sea and the baltic . <EOS> \n",
      "Predicted sequence : nous devrions des mesures sur la mer . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : nous devrions consacrer de l argent a des projets offshore en mer du nord et en mer baltique . <EOS> \n",
      "\n",
      "Update : 11000 ----- Loss : 3.129 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the practice of preparing lists of writers which should not be published reminds one of times we all believed were over . <EOS> \n",
      "Predicted sequence : la pratique des est a ete des nature de comptes qui doit pas un un par un autres nous nous avons tous les . <EOS> . . . . . \n",
      "Target sequence    : la pratique qui consiste a dresser la liste des ecrivains ne devant pas etre publies evoque des temps que nous pensions tous revolus . <EOS> \n",
      "\n",
      "Update : 12000 ----- Loss : 3.171 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they are fully committed to day to day political life and perfect their military formations in the process . <EOS> \n",
      "Predicted sequence : ils sont en effet de la vie des processus . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : en effet tant le hamas le mouvement terroriste islamiste palestinien que le hezbollah son allie strategique libanais mangent pour l instant a tous les <UNK> . <EOS> \n",
      "\n",
      "Update : 13000 ----- Loss : 3.103 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they have no elected governments and almost all have no law making elected parliament . <EOS> \n",
      "Predicted sequence : ils ont ete pas les gouvernements . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : elles ne disposent d aucun gouvernement elu et presque aucune ne dispose d un parlement legislateur elu . <EOS> \n",
      "\n",
      "Update : 14000 ----- Loss : 3.057 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : lv madam president ladies and gentlemen we all know that drug taking is prohibited in sport . <EOS> \n",
      "Predicted sequence : madame madame la presidente mesdames et messieurs nous savons tous que les fait est en de le sport . <EOS> . . . . . . . . . . \n",
      "Target sequence    : lv madame la presidente mesdames et messieurs nous savons tous que le dopage est interdit dans le sport . <EOS> \n",
      "\n",
      "Update : 15000 ----- Loss : 3.088 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president commissioner honourable members mr bowis thank you very much for this productive debate . <EOS> \n",
      "Predicted sequence : monsieur le president monsieur le commissaire chers collegues monsieur le je vous remercie tres pour ce debat sur . <EOS> . . . . . . . . . . . \n",
      "Target sequence    : monsieur le president monsieur le commissaire chers deputes monsieur bowis je vous remercie infiniment pour ce debat productif . <EOS> \n",
      "\n",
      "Update : 16000 ----- Loss : 3.055 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they frequently go unpunished since the eu has different legal and penal systems . <EOS> \n",
      "Predicted sequence : ils ont fait que l ue ont besoin . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : ils restent souvent impunis parce que l ue comprend systemes juridiques et penaux differents . <EOS> \n",
      "\n",
      "Update : 17000 ----- Loss : 2.997 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : many thanks . <EOS> \n",
      "Predicted sequence : merci . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : je vous remercie mille fois . <EOS> \n",
      "\n",
      "Update : 18000 ----- Loss : 2.930 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : some members of my group reject the report because they believe that this is not a european issue . <EOS> \n",
      "Predicted sequence : certains deputes de mon groupe le le rapport parce il ne que ce n est pas une probleme europeen . <EOS> . . . . . . . . . . \n",
      "Target sequence    : certains membres de mon groupe rejettent ce rapport car ils pensent que ce n est pas un theme europeen . <EOS> \n",
      "\n",
      "Update : 19000 ----- Loss : 2.966 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : in its accession treaty it was conceded that finland could maintain its ban on <UNK> and <UNK> until . <EOS> \n",
      "Predicted sequence : dans son adhesion a la commission son <UNK> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : dans son traite d adhesion la finlande a ete autorisee a conserver son interdiction de la <UNK> et de la <UNK> jusqu en . <EOS> \n",
      "\n",
      "Update : 20000 ----- Loss : 2.949 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : as other members have already said since the eu decided to phase out single hull tankers this issue has become more important . <EOS> \n",
      "Predicted sequence : comme des autres deputes ont ont deja dit depuis l ue a decide de la une un difficultes de ce echelle . situation a ete . plus . <EOS> . . \n",
      "Target sequence    : comme d autres deputes l ont deja signale puisque l ue a decide de supprimer progressivement les petroliers a simple coque la question a gagne en importance . <EOS> \n",
      "\n",
      "Update : 21000 ----- Loss : 2.862 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : for a start why if there is to be cooperation with the mediterranean for the thing is called euromed then why not with russia and with other states ? <EOS> \n",
      "Predicted sequence : pour un il cooperation avec la mediterranee est commissaire est est t raison pourquoi pour pourquoi avec la russie ? d autres etats ? <EOS> ? ? ? ? ? ? \n",
      "Target sequence    : premierement pourquoi une cooperation avec la mediterranee le theme s appelle en effet euromed et pas avec la russie ou d autres etats ? <EOS> \n",
      "\n",
      "Update : 22000 ----- Loss : 2.916 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr topolanek the proposed measures are excellent . <EOS> \n",
      "Predicted sequence : m . les amendements . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : monsieur topolanek les mesures proposees sont excellentes . <EOS> \n",
      "\n",
      "Update : 23000 ----- Loss : 2.859 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : these must be created with the agreement of the countries involved otherwise the constitutions of some member states would certainly be infringed . <EOS> \n",
      "Predicted sequence : ces ce ces doivent etre avec avec l accord des pays qui tout doute les ont les des resultats des certains . les pays membres . <EOS> . . . . \n",
      "Target sequence    : en effet ils doivent etre crees avec l accord des pays impliques sans quoi ils poseraient certainement des problemes de constitutionnalite dans certains etats membres . <EOS> \n",
      "\n",
      "Update : 24000 ----- Loss : 2.856 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : refrigeration permits this . <EOS> \n",
      "Predicted sequence : les demande . fait . <EOS> . a . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : la refrigeration le permet . <EOS> \n",
      "\n",
      "Update : 25000 ----- Loss : 2.889 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : relations with burma went through an extremely difficult period during the last meeting we had with the asean group in manila in the philippines . <EOS> \n",
      "Predicted sequence : les relations avec la birmanie ont ete une periode extremement difficile pendant la derniere reunion nous nous avons discute avec le groupe de dans l dans etats . <EOS> . au \n",
      "Target sequence    : les relations avec la birmanie ont connu une situation exceptionnellement difficile durant la derniere reunion que nous avons eue avec le groupe asean a manille aux philippines . <EOS> \n",
      "\n",
      "Update : 26000 ----- Loss : 2.808 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this has since been done and we are grateful for this . <EOS> \n",
      "Predicted sequence : c nous et derniers ont ete faites et . nous le avons avons . . <EOS> . . . . . . . . . . . . . \n",
      "Target sequence    : entre temps ces mesures ont ete effectivement prises et nous lui en sommes reconnaissants . <EOS> \n",
      "\n",
      "Update : 27000 ----- Loss : 2.798 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i think it would be helpful to have an answer from you on this issue . <EOS> \n",
      "Predicted sequence : je pense qu il serait utile de nous avez donner de reponse . cette sujet . <EOS> . a a a . . . . . . . . . . \n",
      "Target sequence    : je crois qu il serait utile que vous nous rappeliez votre position sur ce point . <EOS> \n",
      "\n",
      "Update : 28000 ----- Loss : 2.808 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we should be pleased that you lost for europe was the winner . <EOS> \n",
      "Predicted sequence : nous devrions etre montrer que vous europe pour l est le <UNK> . le ete . <EOS> . . . . . . . . . . . . . . \n",
      "Target sequence    : nous devrions nous rejouir de votre defaite car c est l europe qui a gagne . <EOS> \n",
      "\n",
      "Update : 29000 ----- Loss : 2.789 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : in this respect i would like to congratulate you on the resolution you have just adopted on roma integration . <EOS> \n",
      "Predicted sequence : a cet accord sur la resolution vous . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : a cet egard permettez moi de vous feliciter pour la resolution que vous venez d adopter au sujet de l integration des roms . <EOS> \n",
      "\n",
      "Update : 30000 ----- Loss : 2.792 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : therefore i support the call to cancel haiti s international debt . <EOS> \n",
      "Predicted sequence : par consequent mon soutien de la dette internationale . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : c est pourquoi je suis favorable a l appel a l annulation de la dette exterieure d haiti . <EOS> \n",
      "\n",
      "Update : 31000 ----- Loss : 2.741 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they are victims because they have had the misfortune to be born in a beleaguered country . they are victims because they are desperate and are looking for compassion . <EOS> \n",
      "Predicted sequence : ils sont des victimes parce ils ont ete le possibilite d devenir comme un pays d cas et personnes et ils sont <UNK> et sont . leur qualite . <EOS> . \n",
      "Target sequence    : ce sont des victimes car ils ont eu la malchance de naitre dans un pays de souffrance des victimes car ils sont desesperes et cherchent de la compassion . <EOS> \n",
      "\n",
      "Update : 32000 ----- Loss : 2.749 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : any further delay would rightly be regarded as political . <EOS> \n",
      "Predicted sequence : il convient d abord . <EOS> . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : tout nouveau retard serait a juste titre considere comme d inspiration politique . <EOS> \n",
      "\n",
      "Update : 33000 ----- Loss : 2.666 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : why are we using public money to support people to grow potatoes to make into starch that we cannot use in the eu ? <EOS> \n",
      "Predicted sequence : pourquoi ne nous europeens argent public a soutenir les de reduire de la dans a la violence que l a nous ne pouvons pas utiliser dans l ? <EOS> ? ? \n",
      "Target sequence    : pourquoi depensons nous l argent public pour aider producteurs de pommes de terre destinees a la fabrication de fecule que nous ne pouvons pas utiliser en europe ? <EOS> \n",
      "\n",
      "Update : 34000 ----- Loss : 2.668 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we are therefore suggesting alternative options . <EOS> \n",
      "Predicted sequence : nous sommes donc des autres solutions alternatives <EOS> . . . . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : nous proposons donc d autres pistes . <EOS> \n",
      "\n",
      "Update : 35000 ----- Loss : 2.703 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : only on this basis will it be possible to determine what changes need to be made and to introduce them . <EOS> \n",
      "Predicted sequence : seuls cette mesure est necessaire et d autres . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> seule seule \n",
      "Target sequence    : ce n est que de cette facon que l on pourra definir les changements devant eventuellement etre apportes et les traduire dans les faits . <EOS> \n",
      "\n",
      "Update : 36000 ----- Loss : 2.667 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we are mainstreaming the environment in everything we do . <EOS> \n",
      "Predicted sequence : nous sommes l environnement dans tout ce que nous faisons . <EOS> . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : nous integrons l environnement dans tout ce que nous faisons . <EOS> \n",
      "\n",
      "Update : 37000 ----- Loss : 2.613 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : jokes aside i recognise the exhaustive manner with which the report encompasses the general regulations governing the energy sector . <EOS> \n",
      "Predicted sequence : la a l de reconnais le le rapport de le ce generale les regles generales sur le secteur de l energie . <EOS> . . . . . . . . \n",
      "Target sequence    : blague a part je reconnais que le rapport reprend de maniere exhaustive les reglements generaux regissant le secteur de l energie . <EOS> \n",
      "\n",
      "Update : 38000 ----- Loss : 2.620 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president mr whitehead spoke of the additives survivors network . <EOS> \n",
      "Predicted sequence : monsieur le president m . blair . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : monsieur le president m . whitehead a parle du <UNK> <UNK> network . <EOS> \n",
      "\n",
      "Update : 39000 ----- Loss : 2.649 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the text we have adopted also provides a right to days paternity leave more than the days granted at the moment in france . <EOS> \n",
      "Predicted sequence : le texte nous nous un un droit de bruxelles jour de retard de plus que que les jours en a la italie en france . <EOS> . a a . . \n",
      "Target sequence    : le texte adopte prevoit aussi un droit a un conge de paternite de jours plus que les jours accordes pour l instant en france . <EOS> \n",
      "\n",
      "Update : 40000 ----- Loss : 2.582 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i must say i find it a bit rich for the prime minister of belgium to come along here and tell other nation states what they should do . <EOS> \n",
      "Predicted sequence : je dois dire pour moi le ministre et autres etats membres . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : pour tout dire je trouve un peu fort que le premier ministre belge se presente a nous pour dire a vingt quatre etats nations ce qu ils doivent faire . <EOS> \n",
      "\n",
      "Update : 41000 ----- Loss : 2.625 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the european union has reacted adequately and coherently . <EOS> \n",
      "Predicted sequence : l union europeenne a fait a une est est . la la responsable . <EOS> . a a . . . . . . . . . . . . . \n",
      "Target sequence    : l union europeenne a reagi comme il le fallait et de facon coherente . <EOS> \n",
      "\n",
      "Update : 42000 ----- Loss : 2.587 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i actually believe that from the humanitarian point of view the problem is one of coordination . <EOS> \n",
      "Predicted sequence : je pense qu il s agit de la coordination . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : je crois d ailleurs que d un point de vue humanitaire il s agit d un probleme de coordination . <EOS> \n",
      "\n",
      "Update : 43000 ----- Loss : 2.576 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this situation is unacceptable . <EOS> \n",
      "Predicted sequence : cette est inacceptable . <EOS> . . . a a a a a a a a a a a a a a a a a a a a a \n",
      "Target sequence    : cela est inacceptable . <EOS> \n",
      "\n",
      "Update : 44000 ----- Loss : 2.594 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we shall vote in favour of it . <EOS> \n",
      "Predicted sequence : nous voterons le vote . faveur faveur . <EOS> . a a a a a a a a a a a a a a a a a a a a a \n",
      "Target sequence    : nous soutenons le vote en sa faveur . <EOS> \n",
      "\n",
      "Update : 45000 ----- Loss : 2.567 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : by abolishing the death penalty we will strengthen human dignity and make progress on human rights issues . <EOS> \n",
      "Predicted sequence : en refus la la peine de nous la au niveau des sur questions de l homme . <EOS> . a . . . . . . . . . . . \n",
      "Target sequence    : son abolition renforce la dignite humaine et aide au developpement progressif des droits de l homme . <EOS> \n",
      "\n",
      "Update : 46000 ----- Loss : 2.525 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president i welcome this debate on the budget today . <EOS> \n",
      "Predicted sequence : monsieur monsieur le president je me felicite de ce debat ait ce debat sur le budget . hui . <EOS> . . . . . . . . . . . \n",
      "Target sequence    : en monsieur le president je me rejouis que l on tienne ce debat sur le budget aujourd hui . <EOS> \n",
      "\n",
      "Update : 47000 ----- Loss : 2.568 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : may i depart from normal practice by asking you to pay greater attention to the allocated time slots . <EOS> \n",
      "Predicted sequence : puis moi de voir de pratique idee de de me de etre plus une de point de . l . <EOS> . . . . . . . . . . \n",
      "Target sequence    : permettez moi de formuler une petite remarque exceptionnellement vous pourriez peut etre tenir compte du temps imparti a chacun . <EOS> \n",
      "\n",
      "Update : 48000 ----- Loss : 2.556 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : at the same time the climate crisis is doing more damage to those living in extreme poverty . <EOS> \n",
      "Predicted sequence : parallelement ailleurs la crise climatique est a de a personnes dans vivent dans la pauvrete extreme . <EOS> . a a a . . . . . . . . . \n",
      "Target sequence    : par ailleurs la crise climatique frappe plus durement les personnes qui vivent dans une pauvrete extreme . <EOS> \n",
      "\n",
      "Update : 49000 ----- Loss : 2.566 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we must not permit the use of community funds to finance something that is punishable in these member states . <EOS> \n",
      "Predicted sequence : nous ne devons pas permettre l l fonds communautaires soient un chose de ces dans ces etats membres . <EOS> . a a . . . . . . . . \n",
      "Target sequence    : nous ne devons pas permettre que des fonds communautaires financent quelque chose de sanctionne dans ces etats membres . <EOS> \n",
      "\n",
      "Update : 50000 ----- Loss : 2.596 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this too would be unenforceable . <EOS> \n",
      "Predicted sequence : cela erreur serait serait a claire . <EOS> . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : cette mesure elle aussi serait inapplicable . <EOS> \n",
      "\n",
      "Update : 51000 ----- Loss : 2.541 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it is important though that sound alternative products are available . <EOS> \n",
      "Predicted sequence : il il est important que les produits d controle de sont disponibles . <EOS> . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : toutefois il est important que des produits de substitution sains soient disponibles . <EOS> \n",
      "\n",
      "Update : 52000 ----- Loss : 2.463 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : such a europe will be strong whatever the times . <EOS> \n",
      "Predicted sequence : une telle europe sera forte et que nous la heure . <EOS> . a . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : une telle europe sera forte quelle que soit l epoque . <EOS> \n",
      "\n",
      "Update : 53000 ----- Loss : 2.549 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : moreover deforestation represents the third major factor of global warming . <EOS> \n",
      "Predicted sequence : en outre la deforestation est le troisieme facteur du du rechauffement mondial la planete . <EOS> . . . . . . . . . . . . . . . \n",
      "Target sequence    : en outre la deforestation est le troisieme facteur principal du rechauffement de la planete . <EOS> \n",
      "\n",
      "Update : 54000 ----- Loss : 2.494 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : amnesty international recorded one woman leaving church to find a gang shouting kill the archbishop and kill the priests <EOS> \n",
      "Predicted sequence : amnesty international a l une femme a la existence de trouver un <UNK> <UNK> <UNK> l et ile et a l les <UNK> <EOS> <EOS> <EOS> <EOS> . . . \n",
      "Target sequence    : amnesty international a enregistre une femme quittant l eglise pour rejoindre un groupe <UNK> a mort l archeveque et a mort les pretres . <EOS> \n",
      "\n",
      "Update : 55000 ----- Loss : 2.503 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it leads nations to share and interact with one another respect and better understand each other every day . <EOS> \n",
      "Predicted sequence : elle a a nations et se et un et un faire et qu un les faire chaque moins . <EOS> . . . . . . . . . . . \n",
      "Target sequence    : elle amene les peuples a partager a dialoguer a se respecter et a mieux se comprendre au quotidien . <EOS> \n",
      "\n",
      "Update : 56000 ----- Loss : 2.471 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it may well be that by focusing on that management could have avoided some of its worst mistakes . <EOS> \n",
      "Predicted sequence : il est peut bien il soit basant sur la point de moyens pourraient pu etre certains de ces erreurs erreurs . <EOS> . . . . . . . . . \n",
      "Target sequence    : il se peut qu en se concentrant sur ce point les dirigeants auraient pu eviter certaines de leurs pires erreurs . <EOS> \n",
      "\n",
      "Update : 57000 ----- Loss : 2.439 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : parliament has presented four own initiative reports in this context . firstly there is the rothley report on the settlement of claims relating to traffic accidents . <EOS> \n",
      "Predicted sequence : le parlement ont un ont ete adoptes dans rapport rapport europeen premier rothley a le procedures de par matiere avec les question du accidents . <EOS> . . . . . \n",
      "Target sequence    : quatre rapports d initiative ont ete presentes par le parlement le rapport rothley sur les trafics automobiles en relation avec la responsabilite des accidents . <EOS> \n",
      "\n",
      "Update : 58000 ----- Loss : 2.478 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i must say that the most important responsibility of the european commission and of the european parliament is the internal responsibility to be honest to the citizens of europe . <EOS> \n",
      "Predicted sequence : je dois dire que la responsabilite la la la commission europeenne et du parlement europeen est la responsabilite interne de plus de une aux les citoyens europeens . <EOS> . . \n",
      "Target sequence    : je dois dire que la responsabilite principale de la commission europeenne et du parlement europeen est la responsabilite interne le devoir d honnetete envers les citoyens europeens . <EOS> \n",
      "\n",
      "Update : 59000 ----- Loss : 2.458 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we have spoken of other threats to which i would like to add epidemiological threats and information security for example . <EOS> \n",
      "Predicted sequence : nous avons parle des autres menaces pour je voudrais ajouter des alternatives et et a securite de informations pour exemple . <EOS> . . . . . . . . . \n",
      "Target sequence    : nous avons aborde d autres menaces auxquelles je voudrais ajouter les menaces epidemiologiques et la securite des informations par exemple . <EOS> \n",
      "\n",
      "Update : 60000 ----- Loss : 2.467 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : under these measures some community aid to haiti is suspended . <EOS> \n",
      "Predicted sequence : dans ces mesures communautaire . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : dans le cadre de ces mesures une certaine partie de l aide communautaire a haiti est suspendue . <EOS> \n",
      "\n",
      "Update : 61000 ----- Loss : 2.453 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : of course in the future we shall have work to do to restore the moral credibility of europe as a whole . <EOS> \n",
      "Predicted sequence : bien sur en l avenir nous aurons travaille travail a faire la credibilite morale de l europe dans dans ensemble . <EOS> . . a a a a a a a \n",
      "Target sequence    : bien sur a l avenir nous aurons du travail pour retablir la credibilite morale de l europe comme un tout . <EOS> \n",
      "\n",
      "Update : 62000 ----- Loss : 2.435 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : on the other hand we do recognise that georgia has financing needs and that there is an eu responsibility here . <EOS> \n",
      "Predicted sequence : d autre part a la necessite d autres europeenne . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : par ailleurs nous reconnaissons que la georgie a besoin d un financement et que l ue y a une responsabilite . <EOS> \n",
      "\n",
      "Update : 63000 ----- Loss : 2.416 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the united states is losing markets here in the european union including perhaps in the new member states that joined in . <EOS> \n",
      "Predicted sequence : les etats unis sont les marches dans l union europeenne y compris les etre dans les nouveaux etats membres qui se rejoint a . <EOS> . . . . . . \n",
      "Target sequence    : les etats unis perdent des marches dans l union europeenne y compris peut etre dans les nouveaux etats membres qui ont adhere en . <EOS> \n",
      "\n",
      "Update : 64000 ----- Loss : 2.383 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : under existing regulations information must be entered in the commercial registers of member states and published in national official <UNK> . <EOS> \n",
      "Predicted sequence : dans les base existante des informations existantes etre en dans les grandes commerciaux nombre des etats membres et publies dans les <UNK> officielles nationales . <EOS> . . . . \n",
      "Target sequence    : selon la legislation actuelle les informations doivent etre introduites dans les registres du commerce des etats membres et publiees dans les journaux officiels nationaux . <EOS> \n",
      "\n",
      "Update : 65000 ----- Loss : 2.413 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : in conclusion progress has been visible and measurable but not yet enough and we need to really continue and improve the dynamics . <EOS> \n",
      "Predicted sequence : en conclure les progres ont ete tres et nous mais pas insuffisants loin et nous devons vraiment poursuivre et ameliorer la dynamique . <EOS> . . . . et et et \n",
      "Target sequence    : pour conclure les progres ont ete visibles et mesurables mais sont encore insuffisants et nous devons vraiment poursuivre et ameliorer la dynamique . <EOS> \n",
      "\n",
      "Update : 66000 ----- Loss : 2.379 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : thanks also to my colleague mrs palacio vallelersundi for having made such an excellent job of putting together thoughts in a motion for a resolution on this strategy . <EOS> \n",
      "Predicted sequence : je de mon mon collegue mme palacio a de avoir un un excellent excellent travail de vue de propositions dans une resolution de resolution sur cette strategie . <EOS> . \n",
      "Target sequence    : merci egalement a ma collegue mme palacio vallelersundi d avoir fait un si bon travail en regroupant des reflexions dans une proposition de resolution sur cette strategie . <EOS> \n",
      "\n",
      "Update : 67000 ----- Loss : 2.413 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : if the truth be told this problem was criminally neglected for years . <EOS> \n",
      "Predicted sequence : si est la que <EOS> s dire que ce problematique etait ete ete utilisee depuis . <EOS> . a a . . . . . . . . . . . \n",
      "Target sequence    : c est regrettable ! il faut dire que cette problematique a longtemps ete <UNK> negligee . <EOS> \n",
      "\n",
      "Update : 68000 ----- Loss : 2.361 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we have before us a completely new proposal by parliament very different from that proposed by the commission and with a different outlook from the council . <EOS> \n",
      "Predicted sequence : nous avons par la yeux un nouvelle de adoptee par parlement dans clairement par la que la par commission et avec une large different du la commission du conseil . <EOS> \n",
      "Target sequence    : nous avons sous les yeux une proposition totalement neuve du parlement tres eloignee de ce que proposait la commission et avec un avis different de la part du conseil . <EOS> \n",
      "\n",
      "Update : 69000 ----- Loss : 2.358 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we have seen from johannesburg and from kyoto and elsewhere that they do not pay a jot of attention to what we say . <EOS> \n",
      "Predicted sequence : nous avons dit et kyoto et qu il soit de pas . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : les sommets de johannesbourg de kyoto et d ailleurs sont la pour temoigner du fait qu ils n accordent pas la moindre attention a ce que nous disons . <EOS> \n",
      "\n",
      "Update : 70000 ----- Loss : 2.376 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it should also be possible in other areas to conclude negotiations as soon after that as reasonably possible . <EOS> \n",
      "Predicted sequence : il devrait egalement possible dans les negociations . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : il devrait etre egalement possible dans d autres domaines de conclure les negociations dans les plus brefs delais raisonnables apres cela . <EOS> \n",
      "\n",
      "Update : 71000 ----- Loss : 2.311 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : both systems should operate over entire river basins and take into account the interests of all the countries and regions involved . <EOS> \n",
      "Predicted sequence : les systemes systemes devraient etre dans pied ensemble de zones et et prendre en consideration les interets de tous les pays et les . . <EOS> . . . . . \n",
      "Target sequence    : les deux systemes devraient fonctionner sur l ensemble des bassins hydrographiques et prendre en compte les interets de tous les pays et regions impliques . <EOS> \n",
      "\n",
      "Update : 72000 ----- Loss : 2.395 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the country has been closed to aid workers experts and media for weeks . <EOS> \n",
      "Predicted sequence : le pays a parvenu a organisations des et medias et des medias a des semaines . <EOS> . . . . . . . . . . . . . \n",
      "Target sequence    : le pays est ferme aux secours humanitaires aux experts et aux medias depuis des semaines . <EOS> \n",
      "\n",
      "Update : 73000 ----- Loss : 2.356 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the alternative is a segregated europe with all the attendant problems of discrimination social tension and instability . <EOS> \n",
      "Predicted sequence : l alternative est tout a tous les problemes de la pauvrete . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : l alternative serait une europe <UNK> avec tout ce que cela implique de discrimination d agitation sociale et d instabilite . <EOS> \n",
      "\n",
      "Update : 74000 ----- Loss : 2.392 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : clearly the development of renewables is linked to environmental objectives as well as issues of employment regional development and the promotion of local initiatives . <EOS> \n",
      "Predicted sequence : il developpement des energies renouvelables est lie liee aux des objectifs environnementaux ainsi que aux l emploi et developpement regional et la promotion des initiatives locales . <EOS> . . . \n",
      "Target sequence    : le developpement des energies renouvelables est clairement lie a des objectifs environnementaux ainsi qu a l emploi le developpement regional et la promotion d initiatives locales . <EOS> \n",
      "\n",
      "Update : 75000 ----- Loss : 2.315 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we should ask ourselves what is left of the spirit of these summits . <EOS> \n",
      "Predicted sequence : nous devons nous demander ce qui est la l experience partie . en l . ces pays . <EOS> . a a . . . . . . . a a \n",
      "Target sequence    : nous devrions nous demander ce qui reste de cette grande inspiration mise a jour dans ces sommets . <EOS> \n",
      "\n",
      "Update : 76000 ----- Loss : 2.344 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the matter was referred back to the committee responsible <EOS> \n",
      "Predicted sequence : la sujet a a renvoi ? commission <EOS> <EOS> a a a a a a a a a a a a a a a a a a a a a a \n",
      "Target sequence    : le parlement decide le renvoi en commission <EOS> \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-eb3918e45dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-190-aa18ba23806a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_updates, teacher_forcing_prob, print_every, learning_rate, save_model, beam_size)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mloss_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_tracker = train(model, n_updates = 1000000, print_every=1000, save_model=True, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def show_attention(model, teacher_forcing=True, beam_size=10):\n",
    "    \n",
    "    dataset = train_pairs\n",
    "\n",
    "    inputs, targets_in, targets_out = generate_pairs_batch(np.random.randint(len(dataset)))\n",
    "    inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "    if use_cuda:\n",
    "        inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "\n",
    "    model.decoder._init_hidden(encoder_hidden)\n",
    "\n",
    "    predicted_sequences = torch.zeros(len(targets_in), batch_size).long()\n",
    "    if use_cuda:\n",
    "        predicted_sequences = predicted_sequences.cuda()\n",
    "    attention_weights = torch.zeros(len(inputs), len(targets_out))\n",
    "    \n",
    "    for i in range(len(targets_in)):\n",
    "        output = model.decoder(targets_in[i], encoder_outputs)\n",
    "\n",
    "        attention_weights[:,i] = model.decoder.attn_weights.data[:,0].squeeze()\n",
    "\n",
    "        _, output = torch.max(output, -1)\n",
    "        output = output.view(batch_size)\n",
    "\n",
    "        predicted_sequences[i] = output.data[0]    \n",
    "    \"\"\"\n",
    "    # beam search\n",
    "    # feeding BOS tokens\n",
    "    output = Variable(torch.ones(batch_size).long())\n",
    "    beam_best_seq = torch.zeros(len(targets_in), batch_size, beam_size).long()\n",
    "    beam_best_scores = torch.zeros(batch_size, beam_size)\n",
    "    beam_seq_buffer = torch.zeros(len(targets_in), batch_size, beam_size*beam_size).long()\n",
    "    beam_scores_buffer = torch.zeros(batch_size, beam_size*beam_size)\n",
    "    if use_cuda:\n",
    "        output = output.cuda()\n",
    "        beam_best_seq = beam_best_seq.cuda()\n",
    "        beam_best_scores = beam_best_scores.cuda()\n",
    "        beam_seq_buffer = beam_seq_buffer.cuda()\n",
    "        beam_scores_buffer = beam_scores_buffer.cuda()\n",
    "    for i in range(len(targets_in)):\n",
    "        if i == 0:\n",
    "            output = model.decoder(output, encoder_outputs)\n",
    "            top_vals, top_ix = torch.topk(output, beam_size)\n",
    "            beam_best_scores = top_vals[0].data\n",
    "            beam_best_seq[i] = top_ix.data\n",
    "        else:\n",
    "            for j in range(beam_size):\n",
    "                output = Variable(beam_best_seq[i-1,:,j])\n",
    "                if use_cuda:\n",
    "                    output = output.cuda()\n",
    "                output = model.decoder(output, encoder_outputs)\n",
    "\n",
    "                top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                top_vals = beam_best_scores[:,j].unsqueeze(-1) + top_vals.data\n",
    "\n",
    "                #building buffers\n",
    "                beam_scores_buffer[:,j*beam_size:(j+1)*beam_size] = top_vals\n",
    "\n",
    "                beam_seq_buffer[:i,:,j*beam_size:(j+1)*beam_size] = beam_best_seq[:i,:,j:j+1].repeat(1, 1, beam_size)\n",
    "                beam_seq_buffer[i,:,j*beam_size:(j+1)*beam_size] = top_ix.data\n",
    "\n",
    "            # keeping best beams from buffer\n",
    "            top_vals, top_ix = torch.topk(beam_scores_buffer, beam_size)\n",
    "\n",
    "            # updating best sequences and best scores\n",
    "            beam_best_scores = top_vals\n",
    "\n",
    "\n",
    "            for k in range(batch_size):\n",
    "                for j in range(beam_size):\n",
    "                    ix = top_ix[k,j]\n",
    "                    beam_best_seq[:,k,j] = beam_seq_buffer[:,k,ix]\n",
    "\n",
    "    #re-run with best sequence\n",
    "    best_prediction = beam_best_seq[:,:,0]\n",
    "    best_prediction = Variable(best_prediction)\n",
    "    output = Variable(torch.ones(batch_size)).long()\n",
    "    if use_cuda:\n",
    "        best_prediction = best_prediction.cuda()\n",
    "        output = output.cuda()\n",
    "\n",
    "    for i in range(len(targets_in)):  \n",
    "        output = model.decoder(output, encoder_outputs) \n",
    "\n",
    "        attention_weights[:,i] = model.decoder.attn_weights.data[:,0].squeeze()\n",
    "        output = best_prediction[i]\n",
    "        predicted_sequences[i,:] = output.data\n",
    "    \"\"\"    \n",
    "    #preparing the inputs by removing the padding\n",
    "    attn_in = inputs.data[:,0].cpu().numpy()\n",
    "    # attn_out = targets_out.data[:,0].cpu().numpy()\n",
    "    attn_out = predicted_sequences[:,0]\n",
    "    \n",
    "    while attn_in[-1] != 2:\n",
    "        attn_in = attn_in[:-1]\n",
    "    while attn_out[-1] != 2:\n",
    "        attn_out = attn_out[:-1]\n",
    "    \n",
    "    attention_weights = attention_weights[:len(attn_in), :len(attn_out)]\n",
    "\n",
    "    attn_in_str = [ix2word_src[str(attn_in[i])] for i in range(len(attn_in))]\n",
    "    attn_out_str = [ix2word_tgt[str(attn_out[i])] for i in range(len(attn_out))]\n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))    \n",
    "    ax.matshow(attention_weights.numpy(), cmap='bone')\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + attn_out_str, rotation=90)\n",
    "    ax.set_yticklabels([''] + attn_in_str)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.savefig(\"attention.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ed364d750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_learning_curve(loss_tracker):\n",
    "    \n",
    "    plt.plot(loss_tracker)\n",
    "    plt.show()\n",
    "    \n",
    "loss_tracker_file = 'seq2seq_en_fr_loss.txt'\n",
    "loss_tracker = np.loadtxt(loss_tracker_file)\n",
    "show_learning_curve(loss_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd8fc194d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_attention(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compute_bleu_score(model, n_updates=100, mode='dev', beam_size=2, teacher_forcing=True):\n",
    "    \n",
    "    score = 0\n",
    "    #we do a mean over 100 updates for the BLEU score on the dev and test set\n",
    "    for update in range(n_updates):\n",
    "        \n",
    "        inputs, targets_in, targets_out = generate_pairs_batch(update, mode='dev')\n",
    "        inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "        if use_cuda:\n",
    "            inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "        \n",
    "        model.decoder._init_hidden(encoder_hidden)\n",
    "        \n",
    "        predicted_sequences = torch.zeros(batch_size, len(targets_in)).long()\n",
    "        if use_cuda:\n",
    "            predicted_sequences = predicted_sequences.cuda()\n",
    "        \n",
    "        if teacher_forcing:\n",
    "            for i in range(len(targets_in)):\n",
    "                output = model.decoder(targets_in[i], encoder_outputs)\n",
    "\n",
    "                _, output = torch.max(output, -1)\n",
    "                output = output.view(batch_size)\n",
    "\n",
    "                predicted_sequences[:,i] = output.data\n",
    "        \"\"\"\n",
    "        # beam search\n",
    "        # feeding BOS tokens\n",
    "        output = Variable(torch.ones(batch_size).long())\n",
    "        beam_best_seq = torch.zeros(len(targets_in), batch_size, beam_size).long()\n",
    "        beam_best_scores = torch.zeros(batch_size, beam_size)\n",
    "        beam_seq_buffer = torch.zeros(len(targets_in), batch_size, beam_size*beam_size).long()\n",
    "        beam_scores_buffer = torch.zeros(batch_size, beam_size*beam_size)\n",
    "        if use_cuda:\n",
    "            output = output.cuda()\n",
    "            beam_best_seq = beam_best_seq.cuda()\n",
    "            beam_best_scores = beam_best_scores.cuda()\n",
    "            beam_seq_buffer = beam_seq_buffer.cuda()\n",
    "            beam_scores_buffer = beam_scores_buffer.cuda()\n",
    "        for i in range(len(targets_in)):\n",
    "            if i == 0:\n",
    "                output = model.decoder(output, encoder_outputs)\n",
    "                top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                beam_best_scores = top_vals[0].data\n",
    "                beam_best_seq[i] = top_ix.data\n",
    "            else:\n",
    "                for j in range(beam_size):\n",
    "                    output = Variable(beam_best_seq[i-1,:,j])\n",
    "                    if use_cuda:\n",
    "                        output = output.cuda()\n",
    "                    output = model.decoder(output, encoder_outputs)\n",
    "\n",
    "                    top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                    top_vals = beam_best_scores[:,j].unsqueeze(-1) + top_vals.data\n",
    "\n",
    "                    #building buffers\n",
    "                    beam_scores_buffer[:,j*beam_size:(j+1)*beam_size] = top_vals\n",
    "\n",
    "                    beam_seq_buffer[:i,:,j*beam_size:(j+1)*beam_size] = beam_best_seq[:i,:,j:j+1].repeat(1, 1, beam_size)\n",
    "                    beam_seq_buffer[i,:,j*beam_size:(j+1)*beam_size] = top_ix.data\n",
    "\n",
    "                # keeping best beams from buffer\n",
    "                top_vals, top_ix = torch.topk(beam_scores_buffer, beam_size)\n",
    "\n",
    "                # updating best sequences and best scores\n",
    "                beam_best_scores = top_vals\n",
    "\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    for j in range(beam_size):\n",
    "                        ix = top_ix[k,j]\n",
    "                        beam_best_seq[:,k,j] = beam_seq_buffer[:,k,ix]\n",
    "\n",
    "        #re-run with best sequence\n",
    "        best_prediction = beam_best_seq[:,:,0]\n",
    "        best_prediction = Variable(best_prediction)\n",
    "        output = Variable(torch.ones(batch_size)).long()\n",
    "        if use_cuda:\n",
    "            best_prediction = best_prediction.cuda()\n",
    "            output = output.cuda()\n",
    "\n",
    "        for i in range(len(targets_in)):  \n",
    "\n",
    "            output = best_prediction[i]\n",
    "\n",
    "            predicted_sequences[:,i] = output.data\n",
    "        \"\"\"  \n",
    "        for j in range(batch_size):\n",
    "            \"\"\"\n",
    "            output = ''.join(str(ix2word_tgt[str(word)]) + ' ' for word in predicted_sequences[j] if word not in [0, 1, 2, 3, int(word2ix_src['.'])])\n",
    "            reference = ''.join(str(ix2word_tgt[str(word)]) + ' ' for word in targets_out[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])])\n",
    "            \n",
    "            with open('output', 'w') as output_file:\n",
    "                output_file.write(output)\n",
    "\n",
    "            with open('reference', 'w') as reference_file:\n",
    "                reference_file.write(reference)\n",
    "\n",
    "            from os import system\n",
    "            x = system('./multi-bleu.perl reference < output')\n",
    "#             score += tmp\n",
    "            \"\"\"\n",
    "            \n",
    "            output = [str(ix2word_tgt[str(word)]) for word in predicted_sequences[j] if word not in [0, 1, 2, 3, int(word2ix_src['.'])]]\n",
    "            reference = [str(ix2word_tgt[str(word)]) for word in targets_out[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])]]\n",
    "            try:\n",
    "                tmp = sentence_bleu(reference,output)\n",
    "            except:\n",
    "                pass\n",
    "            if tmp > 0.7:\n",
    "                print('Source : ' + ''.join(str(ix2word_src[str(word)]) + \" \" for word in inputs[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])]))\n",
    "                print('Output : ' + ''.join(str(ix2word_tgt[str(word)]) + \" \" for word in predicted_sequences[j] if word not in [0, 1, 2, 3, int(word2ix_src['.'])]))\n",
    "                print('Target : ' + ''.join(str(ix2word_tgt[str(word)]) + \" \" for word in targets_out[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])]))\n",
    "            \n",
    "        \n",
    "    score = score * 100 / (batch_size * n_updates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('a',)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-b80142610145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_bleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-212-826e3f362a23>\u001b[0m in \u001b[0;36mcompute_bleu_score\u001b[0;34m(model, n_updates, mode, beam_size, teacher_forcing)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix2word_tgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2ix_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Source : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix2word_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2ix_src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/translate/bleu_score.pyc\u001b[0m in \u001b[0;36msentence_bleu\u001b[0;34m(references, hypothesis, weights, smoothing_function, auto_reweigh, emulate_multibleu)\u001b[0m\n\u001b[1;32m     87\u001b[0m     return corpus_bleu([references], [hypothesis],\n\u001b[1;32m     88\u001b[0m                         \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_reweigh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                         emulate_multibleu)\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/translate/bleu_score.pyc\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh, emulate_multibleu)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# denominator for the corpus-level modified precision.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mp_numerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mp_denominators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/translate/bleu_score.pyc\u001b[0m in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# Assigns the intersection between hypothesis and references' counts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     clipped_counts = {ngram: min(count, max_counts[ngram])\n\u001b[0;32m--> 304\u001b[0;31m                       for ngram, count in counts.items()}\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nltk/translate/bleu_score.pyc\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((ngram, count))\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;31m# Assigns the intersection between hypothesis and references' counts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     clipped_counts = {ngram: min(count, max_counts[ngram])\n\u001b[0;32m--> 304\u001b[0;31m                       for ngram, count in counts.items()}\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('a',)"
     ]
    }
   ],
   "source": [
    "compute_bleu_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score : 0.2428\n"
     ]
    }
   ],
   "source": [
    "compute_bleu_score(model, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 24 16:10:37 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 27%   39C    P2    32W / 120W |    714MiB /  6069MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1290      G   /usr/lib/xorg/Xorg                           200MiB |\n",
      "|    0      3171      G   compiz                                        41MiB |\n",
      "|    0      5456      G   ...24328740,131072 --enable-crash-reporter    40MiB |\n",
      "|    0      5669      C   /usr/bin/python2                             427MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 15:36:05 up 4 min,  1 user,  load average: 1.62, 1.45, 0.66\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 340 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 339 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 28.7 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  4.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m 21.2 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 42.4 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  1.8 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  1.7 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383692 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  6748444 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  6467688 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  3167560 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  9405160 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3974 patrice   20   0 1242620 198268  77952 S  12.5  1.2   0:30.56 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3285 patrice   20   0 1023196 114152  68972 S   6.2  0.7   0:02.50 compiz      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3937 patrice   20   0  626056 171800  95372 S   6.2  1.0   0:09.11 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4084 patrice   20   0 1276816 203504  59420 S   6.2  1.2   0:06.55 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185576   6192   3980 S   0.0  0.0   0:01.01 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    3 root      20   0       0      0      0 S   0.0  0.0   0:00.08 kworker/0:0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    5 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kworker/u8+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.39 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
