{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 50\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DATADIR = 'data/'\n",
    "\n",
    "word2ix_src_file = 'word2ix_en_filtered.json'\n",
    "ix2word_src_file = 'ix2word_en_filtered.json'\n",
    "word2ix_tgt_file = 'word2ix_fr_filtered.json'\n",
    "ix2word_tgt_file = 'ix2word_fr_filtered.json'\n",
    "\n",
    "pairs_file = 'pairs_en_fr_filtered.json'\n",
    "\n",
    "with open(DATADIR + word2ix_src_file) as f:\n",
    "    word2ix_src = json.load(f)\n",
    "with open(DATADIR + ix2word_src_file) as f:\n",
    "    ix2word_src = json.load(f)\n",
    "with open(DATADIR + word2ix_tgt_file) as f:\n",
    "    word2ix_tgt = json.load(f)\n",
    "with open(DATADIR + ix2word_tgt_file) as f:\n",
    "    ix2word_tgt = json.load(f)\n",
    "\n",
    "with open(DATADIR + pairs_file) as f:\n",
    "    pairs = json.load(f)\n",
    "    \n",
    "source_vocab_size = len(word2ix_src)\n",
    "target_vocab_size = len(word2ix_tgt)\n",
    "\n",
    "n_pairs = len(pairs)\n",
    "np.random.shuffle(pairs)\n",
    "\n",
    "#split into three subsets (train, dev, test)\n",
    "train_pairs = pairs[:(9 * n_pairs// 10)] #90%\n",
    "dev_pairs = pairs[(9 * n_pairs // 10):(19 * n_pairs // 20)] #5%\n",
    "test_pairs = pairs[(19 * n_pairs // 20):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs_batch(update_num, mode='train'):\n",
    "    #0 is UNK, 1 is BOS, 2 is EOS, 3 is PAD\n",
    "    #bos is only used in target_in\n",
    "    # i is # of update\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = train_pairs\n",
    "    elif mode == 'dev':\n",
    "        dataset = dev_pairs\n",
    "    elif mode == 'test':\n",
    "        dataset = test_pairs\n",
    "        \n",
    "    num_pairs = len(dataset)\n",
    "    \n",
    "    index = (update_num * batch_size) % len(dataset)\n",
    "    \n",
    "    pair = dataset[index]\n",
    "    \n",
    "    inputs = pair['source']\n",
    "    targets_in = pair['target']\n",
    "    targets_out = pair['target']\n",
    "\n",
    "    # add <BOS> and <EOS> tokens\n",
    "    inputs = inputs + [int(word2ix_src['<EOS>'])]\n",
    "    targets_in = [int(word2ix_tgt['<BOS>'])] + targets_in\n",
    "    targets_out = targets_out + [int(word2ix_tgt['<EOS>'])]    \n",
    "\n",
    "    inputs = torch.LongTensor(inputs).unsqueeze(1)\n",
    "    targets_in = torch.LongTensor(targets_in).unsqueeze(1)\n",
    "    targets_out = torch.LongTensor(targets_out).unsqueeze(1)\n",
    "    \n",
    "    return inputs, targets_in, targets_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, source_vocab_size, target_vocab_size, embedding_size=256, hidden_size=256,\n",
    "                 attention_size=256, num_layers=1, max_seq_len=30):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        \n",
    "        self.encoder = Encoder(input_size=source_vocab_size, \n",
    "                               embedding_size=embedding_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               num_layers=num_layers)\n",
    "        \n",
    "        self.decoder = Decoder(output_size=target_vocab_size,\n",
    "                               embedding_size=embedding_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               attention_size=attention_size,\n",
    "                               num_layers=num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_size=256, hidden_size=256,\n",
    "                 num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden0 = nn.Parameter(torch.zeros(2*num_layers, 1, hidden_size))\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n",
    "        self.encoder_rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, \n",
    "                                  num_layers=num_layers, bidirectional=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self._init_hidden()\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.encoder_rnn(x, hidden)\n",
    "        \n",
    "        return x, hidden\n",
    "\n",
    "    def _init_hidden(self):\n",
    "        # initial hidden state is a learned bias parameter\n",
    "        hidden = self.hidden0.clone().repeat(1, batch_size, 1)\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_size, embedding_size=256, hidden_size=256,\n",
    "                 attention_size=256, num_layers=1):\n",
    "        \"\"\"\n",
    "        We use the original attention mechanism from Bahdanau et al. 2014\n",
    "        The layers are of this model correspond to the following notation in the original paper.\n",
    "        \n",
    "        attn_fc_prev_hid : Wa\n",
    "        attn_fc_enc_hid : Ua\n",
    "        attn_fc_context : va\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        \n",
    "        # attention\n",
    "        self.attn_fc_prev_hid = nn.Linear(in_features=hidden_size, \n",
    "                                          out_features=attention_size)\n",
    "        self.attn_fc_enc_hid = nn.Linear(in_features=2*hidden_size, \n",
    "                                         out_features=attention_size)\n",
    "        self.attn_fc_context = nn.Linear(in_features=attention_size,\n",
    "                                         out_features=1)\n",
    "    \n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)    \n",
    "        self.decoder_rnn = nn.GRU(input_size=(embedding_size + 2 * hidden_size), \n",
    "                                  hidden_size=hidden_size, \n",
    "                                  num_layers=num_layers)\n",
    "        self.clf = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, encoder_outputs):\n",
    "        \n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        # attention\n",
    "        tmp1 = self.attn_fc_prev_hid(self.hidden)\n",
    "        tmp2 = self.attn_fc_enc_hid(encoder_outputs)\n",
    "\n",
    "        context_weights = self.attn_fc_context(F.tanh(tmp1 + tmp2))\n",
    "        context_weights = F.softmax(context_weights, 0)\n",
    "        self.attn_weights = context_weights #for attention plotting purposes\n",
    "        \n",
    "        context_weights = context_weights.permute(1, 2, 0) # (batch size x 1 x seq_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # (batch size x seq_len x 2*hidden_dim)\n",
    "\n",
    "        context_vector = torch.bmm(context_weights, encoder_outputs)\n",
    "        context_vector = context_vector.permute(1, 0, 2) # (1 x batch_size x 2*hidden_dim)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        #concatenate previously predicted word embedding and context vector\n",
    "        x = torch.cat((x, context_vector), dim=-1)\n",
    "        x, self.hidden = self.decoder_rnn(x, self.hidden)\n",
    "        x = self.clf(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_hidden(self, encoder_hidden_state):\n",
    "        self.hidden = encoder_hidden_state[0].view(1, batch_size, -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_updates=10000, teacher_forcing_prob=0.5, print_every=100, \n",
    "          learning_rate=1e-3, save_model=False):\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_buffer = []\n",
    "    loss_tracker = []\n",
    "\n",
    "    # + 1 to show the last update\n",
    "    for update in range(n_updates + 1):\n",
    "        \n",
    "        loss = 0\n",
    "        teacher_forcing = True if np.random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, targets_in, targets_out = generate_pairs_batch(update)\n",
    "\n",
    "        inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "        if use_cuda:\n",
    "            inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "        \n",
    "        model.decoder._init_hidden(encoder_hidden)\n",
    "                        \n",
    "        if teacher_forcing:\n",
    "            predicted_sequence = torch.zeros(len(targets_in)).long()\n",
    "            if use_cuda:\n",
    "                predicted_sequence = predicted_sequence.cuda()\n",
    "            for i in range(len(targets_in)):\n",
    "                output = model.decoder(targets_in[i], encoder_outputs)\n",
    "                \n",
    "                loss += criterion(output.view(batch_size, -1), targets_out[i])\n",
    "\n",
    "                _, output = torch.max(output, -1)\n",
    "                output = output.view(batch_size)\n",
    "                predicted_sequence[i] = output.data[0]\n",
    "        else:\n",
    "            predicted_sequence = torch.ones(max_seq_len).long() * int(word2ix_tgt['<PAD>'])\n",
    "            if use_cuda:\n",
    "                predicted_sequence = predicted_sequence.cuda()\n",
    "            # feeding BOS tokens for i=0\n",
    "            output = Variable(torch.ones(batch_size).long())\n",
    "            if use_cuda:\n",
    "                output = output.cuda()\n",
    "            #pad flag when predicted sequence is longer than target sequence\n",
    "            pad = Variable(torch.ones(batch_size).long() * int(word2ix_tgt['<EOS>']))\n",
    "            if use_cuda:\n",
    "                pad = pad.cuda()\n",
    "            for i in range(max_seq_len):\n",
    "                output = model.decoder(output, encoder_outputs)\n",
    "                if i < len(targets_out):\n",
    "                    loss += criterion(output.view(batch_size, -1), targets_out[i])\n",
    "                else:\n",
    "                    loss += criterion(output.view(batch_size, -1), pad)\n",
    "\n",
    "                _, output = torch.max(output, -1)\n",
    "                output = output.view(batch_size)\n",
    "                predicted_sequence[i] = output.data[0]\n",
    "                if predicted_sequence[i] == int(word2ix_tgt['<EOS>']):\n",
    "                    break\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        loss_buffer.append(loss.data[0])\n",
    "\n",
    "        if update % print_every == 0:\n",
    "            \n",
    "            if teacher_forcing:\n",
    "                print(\"TEACHER FORCING\")\n",
    "            else:\n",
    "                print(\"NO TEACHER FORCING\")\n",
    "            \n",
    "            inputs = inputs[:,0]\n",
    "            targets_out = targets_out[:,0]\n",
    "            \n",
    "#             print(inputs)\n",
    "#             print(predicted_sequence)\n",
    "#             print(targets_out)\n",
    "            \n",
    "            # convert all sequence to list (easier to read)\n",
    "            inputs = [str(inputs.data[i]) for i in range(len(inputs))]\n",
    "            predicted_sequence = [str(predicted_sequence[i]) for i in range(len(predicted_sequence))]\n",
    "            targets_out = [str(targets_out.data[i]) for i in range(len(targets_out))]\n",
    "\n",
    "            # create string of sentence\n",
    "            og_sequence = ''.join(ix2word_src[elem] + ' ' for elem in inputs if ix2word_tgt[elem] != '<PAD>')\n",
    "            pred_sequence = ''.join(ix2word_tgt[elem] + ' ' for elem in predicted_sequence if ix2word_tgt[elem] != '<PAD>')\n",
    "            target_sequence = ''.join(ix2word_tgt[elem] + ' ' for elem in targets_out if ix2word_tgt[elem] != '<PAD>')\n",
    "            \n",
    "            #mean over print_every batches of loss\n",
    "            loss_tracker.append(np.mean(loss_buffer))\n",
    "            loss_buffer = []\n",
    "            \n",
    "            print(\"Update : %d ----- Loss : %.3f\\n-----------------------------\" % (update, loss_tracker[-1]))\n",
    "            print(\"Original sequence  : %s\" % og_sequence)\n",
    "            print(\"Predicted sequence : %s\" % pred_sequence)\n",
    "            print(\"Target sequence    : %s\\n\" % target_sequence)\n",
    "            \n",
    "            if save_model:\n",
    "                #saving encoder and decoder separately\n",
    "                torch.save(model.encoder.state_dict(), 'seq2seq_encoder_en_fr.pt')\n",
    "                torch.save(model.decoder.state_dict(), 'seq2seq_decoder_en_fr.pt')\n",
    "                \n",
    "                #saving loss progress\n",
    "                np.savetxt('seq2seq_en_fr_loss.txt', np.array(loss_tracker))\n",
    "    \n",
    "    return loss_tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(source_vocab_size=source_vocab_size, target_vocab_size=target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.load_state_dict(torch.load('seq2seq_encoder_en_fr.pt'))\n",
    "model.decoder.load_state_dict(torch.load('seq2seq_decoder_en_fr.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEACHER FORCING\n",
      "Update : 0 ----- Loss : 42.657\n",
      "-----------------------------\n",
      "Original sequence  : here too there is just one small unresolved issue . <EOS> \n",
      "Predicted sequence : il il il est il seul point . . pas . <EOS> \n",
      "Target sequence    : ici aussi il subsiste un seul point mineur non resolu . <EOS> \n",
      "\n",
      "TEACHER FORCING\n",
      "Update : 1000 ----- Loss : 142.964\n",
      "-----------------------------\n",
      "Original sequence  : with the genetically modified soya seeds used this year in the usa for food production we have seen the first genetically modified plant raw goods arrive in europe . <EOS> \n",
      "Predicted sequence : le est pourquoi la commission de la le de dans le objectif a a est ete le region a etats unis dans nous etats communautaires . . . . . . les politique du . matiere . <EOS> \n",
      "Target sequence    : c est avec la culture de soja genetiquement modifie pour l industrie alimentaire qui a debute cette annee aux etats unis que des matieres premieres vegetales modifiees genetiquement sont arrivees pour la premiere fois en europe . <EOS> \n",
      "\n",
      "NO TEACHER FORCING\n",
      "Update : 2000 ----- Loss : 154.624\n",
      "-----------------------------\n",
      "Original sequence  : the union s common objectives should be promoted within the context of such cooperation and no member state should be excluded from participating . <EOS> \n",
      "Predicted sequence : la la union europeenne a la l union doit etre etre etre a la la la la la la la la de l un etre <EOS> \n",
      "Target sequence    : il faut promouvoir les objectifs communs a l ensemble de l union dans le cadre de cette cooperation et aucun etat membre ne doit en etre exclu . <EOS> \n",
      "\n",
      "NO TEACHER FORCING\n",
      "Update : 3000 ----- Loss : 155.790\n",
      "-----------------------------\n",
      "Original sequence  : this allows citizens to experience europe at first hand because the funding has a local impact . <EOS> \n",
      "Predicted sequence : ce qui est a pas une une une une une question de de \n",
      "Target sequence    : ce financement a un impact local et permet aux citoyens d avoir une connaissance directe de l europe . <EOS> \n",
      "\n",
      "NO TEACHER FORCING\n",
      "Update : 4000 ----- Loss : 152.022\n",
      "-----------------------------\n",
      "Original sequence  : imposing such a sunset clause is clearly not in line with the recent agreement on the revised comitology procedure . <EOS> \n",
      "Predicted sequence : il est vrai de la de l de de de de la de a \n",
      "Target sequence    : l imposition d une telle clause de suppression automatique n est clairement pas conforme au recent accord sur la procedure de comitologie revisee . <EOS> \n",
      "\n",
      "TEACHER FORCING\n",
      "Update : 5000 ----- Loss : 152.840\n",
      "-----------------------------\n",
      "Original sequence  : let me recall that this memorandum of understanding gives a breathing space to the european industry giving it extra time to adjust . <EOS> \n",
      "Predicted sequence : j moi de l que l debat de un de a bonne de un . l union . . il est a . . la . l est . <EOS> \n",
      "Target sequence    : permettez moi de rappeler que ce protocole d accord offre une bouffee d oxygene a l industrie europeenne qu il lui laisse davantage de temps pour s ajuster . <EOS> \n",
      "\n",
      "NO TEACHER FORCING\n",
      "Update : 6000 ----- Loss : 152.850\n",
      "-----------------------------\n",
      "Original sequence  : that was a compromise . <EOS> \n",
      "Predicted sequence : il est un un a un un \n",
      "Target sequence    : il s agissait d un compromis . <EOS> \n",
      "\n",
      "NO TEACHER FORCING\n",
      "Update : 7000 ----- Loss : 152.153\n",
      "-----------------------------\n",
      "Original sequence  : achieving these results and perhaps i uncharacteristically understate the point is not without obstacles . <EOS> \n",
      "Predicted sequence : le le le le le le le le le le le le le parlement europeen et ne de pas \n",
      "Target sequence    : la voie vers la realisation de ces objectifs et je minimise peut etre ce point de maniere non caracteristique n est pas sans embuches . <EOS> \n",
      "\n",
      "TEACHER FORCING\n",
      "Update : 8000 ----- Loss : 154.009\n",
      "-----------------------------\n",
      "Original sequence  : the council has attacked the position of the parliament at its core and damaged it ! <EOS> \n",
      "Predicted sequence : la le parlement le le parlement de la le article du la commission du parlement . <EOS> \n",
      "Target sequence    : dans ce cas ci le conseil a detruit l essence de la position du parlement ! <EOS> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_tracker = train(model, n_updates = 1000000, print_every=1000, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def show_attention(model, teacher_forcing=True):\n",
    "    \n",
    "    inputs, targets_in, targets_out = generate_pairs_batch()\n",
    "    inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "    if use_cuda:\n",
    "        inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "\n",
    "    model.decoder._init_hidden(encoder_hidden)\n",
    "\n",
    "    predicted_sequence = torch.zeros(len(targets_in)).long()\n",
    "    if use_cuda:\n",
    "        predicted_sequence = predicted_sequence.cuda()\n",
    "        \n",
    "    attention_weights = torch.zeros(len(inputs), len(targets_out))\n",
    "\n",
    "    for i in range(len(targets_in)):\n",
    "        if teacher_forcing:\n",
    "            output = model.decoder(targets_in[i], encoder_outputs)\n",
    "        else:\n",
    "            if i == 0:\n",
    "                # feeding BOS tokens\n",
    "                output = torch.ones((1, batch_size)).long()                \n",
    "            output = model.decoder(output, encoder_outputs) \n",
    "                    \n",
    "        attention_weights[:,i] = model.decoder.attn_weights.data[:,0].squeeze()\n",
    "\n",
    "        _, predicted_word = torch.max(output, -1)\n",
    "        predicted_word = predicted_word.view(batch_size)\n",
    "        predicted_sequence[i] = predicted_word.data[0]\n",
    "    \n",
    "    #preparing the inputs by removing the padding\n",
    "    attn_in = inputs.data[:,0].cpu().numpy()\n",
    "    # attn_out = targets_out.data[:,0].cpu().numpy()\n",
    "    attn_out = predicted_sequence\n",
    "    \n",
    "    while attn_in[-1] != 2:\n",
    "        attn_in = attn_in[:-1]\n",
    "    while attn_out[-1] != 2:\n",
    "        attn_out = attn_out[:-1]\n",
    "    \n",
    "    attention_weights = attention_weights[:len(attn_in), :len(attn_out)]\n",
    "\n",
    "    attn_in_str = [ix2word_src[str(attn_in[i])] for i in range(len(attn_in))]\n",
    "    attn_out_str = [ix2word_tgt[str(attn_out[i])] for i in range(len(attn_out))]\n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))    \n",
    "    ax.matshow(attention_weights.numpy(), cmap='bone')\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + attn_out_str, rotation=90)\n",
    "    ax.set_yticklabels([''] + attn_in_str)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.savefig(\"attention.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ed364d750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_learning_curve(loss_tracker):\n",
    "    \n",
    "    plt.plot(loss_tracker)\n",
    "    plt.show()\n",
    "    \n",
    "loss_tracker_file = 'seq2seq_en_fr_loss.txt'\n",
    "loss_tracker = np.loadtxt(loss_tracker_file)\n",
    "show_learning_curve(loss_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(source_vocab_size=source_vocab_size, target_vocab_size=target_vocab_size)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# pretrained model\n",
    "pretrained_encoder_file = 'seq2seq_encoder_en_fr.pt'\n",
    "pretrained_decoder_file = 'seq2seq_decoder_en_fr.pt'\n",
    "model.encoder.load_state_dict(torch.load(pretrained_encoder_file))\n",
    "model.decoder.load_state_dict(torch.load(pretrained_decoder_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "21\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4de6ce1a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_attention(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compute_bleu_score(model, n_updates=100, mode='dev'):\n",
    "    \n",
    "    score = 0\n",
    "    #we do a mean over 100 updates for the BLEU score on the dev and test set\n",
    "    for update in range(n_updates):\n",
    "        inputs, _, targets_out = generate_pairs_batch(update, mode=mode)\n",
    "    \n",
    "        \n",
    "        \n",
    "        score = +=sentence_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 20 19:37:07 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 25%   35C    P2    25W / 120W |   5945MiB /  6069MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1191      G   /usr/lib/xorg/Xorg                           208MiB |\n",
      "|    0      3773      C   /usr/bin/python2                            5251MiB |\n",
      "|    0      8274      G   compiz                                        51MiB |\n",
      "|    0     10523      G   ...6318934,131072 --enable-crash-reporter=    42MiB |\n",
      "|    0     10886      C   /usr/bin/python2                             387MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 19:36:16 up  6:48,  1 user,  load average: 0.94, 0.59, 0.42\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 340 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   2 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 338 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  6.7 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.9 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 92.0 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383700 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  1088484 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 14751352 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m   543864 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 15165668 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  1563416 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  1133212 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m10569 patrice   20   0 1224372 140952  47316 R  18.8  0.9   1:11.23 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2458 root      20   0  399720   7832   1428 S   6.2  0.0   0:34.56 docker-con+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10458 patrice   20   0 1301448 180392  65436 S   6.2  1.1   0:29.84 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10523 patrice   20   0  613752 141220  50260 S   6.2  0.9   0:18.49 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10686 patrice   20   0 1258864 115500  16840 S   6.2  0.7   0:35.15 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m11447 patrice   20   0   41928   3616   2976 R   6.2  0.0   0:00.01 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185500    596    180 S   0.0  0.0   0:01.15 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.06 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:23.18 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.04 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 19:36:19 up  6:48,  1 user,  load average: 0.86, 0.58, 0.42\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 340 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 339 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  8.1 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  2.4 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 89.3 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383700 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  1091764 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 14751312 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m   540624 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 15165720 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  1563364 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  1137636 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m10569 patrice   20   0 1220276 138552  44728 S  15.9  0.8   1:11.71 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10523 patrice   20   0  609656 137380  46600 S   4.0  0.8   0:18.61 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10686 patrice   20   0 1258864 115664  16840 S   3.6  0.7   0:35.26 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10458 patrice   20   0 1301448 180392  65436 S   3.3  1.1   0:29.94 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10886 patrice   20   0 20.627g 6.292g 101544 S   3.0 40.3   0:42.93 python2     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1191 root      20   0  316836  36880  29004 S   1.3  0.2   0:15.24 Xorg        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8274 patrice   20   0 1179936 129532  35260 S   0.7  0.8   0:44.70 compiz      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1222 root     -51   0       0      0      0 S   0.3  0.0   0:46.21 irq/130-nv+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8056 patrice   20   0  166532   1156    908 S   0.3  0.0   0:00.18 gpg-agent   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m11109 root      20   0       0      0      0 S   0.3  0.0   0:00.26 kworker/3:2 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m11413 patrice   20   0 1763652 184816  73580 S   0.3  1.1   0:02.86 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m11447 patrice   20   0   41928   3616   2976 R   0.3  0.0   0:00.02 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185500    596    180 S   0.0  0.0   0:01.15 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.06 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:23.18 rcu_sched   \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 19:36:22 up  6:48,  1 user,  load average: 0.86, 0.58, 0.42\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 339 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 338 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  6.6 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  2.1 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 91.1 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383700 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  1108664 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 14734344 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m   540692 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 15165780 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  1563304 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  1154624 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m10569 patrice   20   0 1220020 138408  44584 S  12.6  0.8   1:12.09 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10523 patrice   20   0  609656 140464  49640 S   4.3  0.9   0:18.74 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10686 patrice   20   0 1258864 115664  16840 S   4.0  0.7   0:35.38 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10886 patrice   20   0 20.627g 6.292g 101544 S   2.7 40.3   0:43.01 python2     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10458 patrice   20   0 1299400 180556  65592 S   2.3  1.1   0:30.01 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1191 root      20   0  316836  36880  29004 S   1.0  0.2   0:15.27 Xorg        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1222 root     -51   0       0      0      0 S   1.0  0.0   0:46.24 irq/130-nv+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8274 patrice   20   0 1179936 129532  35260 S   0.7  0.8   0:44.72 compiz      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1255 root      20   0   44024    512    280 S   0.3  0.0   0:00.60 wpa_suppli+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2412 root      20   0  621536   2988    264 S   0.3  0.0   0:26.22 dockerd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2458 root      20   0  399720   7832   1428 S   0.3  0.0   0:34.57 docker-con+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10434 patrice   20   0  471072  72272   4680 S   0.3  0.4   0:03.88 jupyter-lab \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10537 root      20   0       0      0      0 S   0.3  0.0   0:00.39 kworker/u8+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m11447 patrice   20   0   41928   3616   2976 R   0.3  0.0   0:00.03 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185500    596    180 S   0.0  0.0   0:01.15 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 19:36:25 up  6:48,  1 user,  load average: 0.87, 0.58, 0.42\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 339 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   2 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 337 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  9.4 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  1.7 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 88.7 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383700 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  1078896 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 14742644 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m   562160 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 15165828 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  1563256 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  1125016 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m10569 patrice   20   0 1241524 159724  65660 S  21.9  1.0   1:12.75 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10523 patrice   20   0  639096 169656  79088 S   8.3  1.0   0:18.99 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m10686 patrice   20   0 1258864 115816  16840 R   3.3  0.7   0:35.48 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10886 patrice   20   0 20.627g 6.292g 101544 S   3.0 40.3   0:43.10 python2     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10458 patrice   20   0 1299400 180276  65604 S   2.0  1.1   0:30.07 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1222 root     -51   0       0      0      0 S   1.3  0.0   0:46.28 irq/130-nv+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1191 root      20   0  316836  36880  29004 S   0.7  0.2   0:15.29 Xorg        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8274 patrice   20   0 1179936 129532  35260 S   0.7  0.8   0:44.74 compiz      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m11109 root      20   0       0      0      0 S   0.7  0.0   0:00.28 kworker/3:2 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.3  0.0   0:23.19 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m11447 patrice   20   0   41928   3616   2976 R   0.3  0.0   0:00.04 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185500    596    180 S   0.0  0.0   0:01.15 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.06 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 19:36:28 up  6:48,  1 user,  load average: 0.87, 0.58, 0.42\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 339 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 338 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 14.3 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  3.5 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 81.4 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.6 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383700 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  1093724 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 14743720 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m   546256 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 15165856 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  1563228 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  1141280 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m10569 patrice   20   0 1224116 144444  50052 S  32.5  0.9   1:13.73 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10523 patrice   20   0  621688 152504  61680 S   9.6  0.9   0:19.28 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10458 patrice   20   0 1299400 181336  66760 S   6.6  1.1   0:30.27 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10686 patrice   20   0 1258864 115980  16840 S   3.6  0.7   0:35.59 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1191 root      20   0  316836  36880  29004 S   3.0  0.2   0:15.38 Xorg        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10886 patrice   20   0 20.627g 6.292g 101544 S   3.0 40.3   0:43.19 python2     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8274 patrice   20   0 1179936 129532  35260 S   1.7  0.8   0:44.79 compiz      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1222 root     -51   0       0      0      0 S   0.7  0.0   0:46.30 irq/130-nv+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10434 patrice   20   0  471072  72272   4680 S   0.7  0.4   0:03.90 jupyter-lab \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m  975 message+  20   0   45504   2724    928 S   0.3  0.0   0:06.86 dbus-daemon \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2412 root      20   0  621536   2988    264 S   0.3  0.0   0:26.23 dockerd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3065 root      20   0   12660    844    212 S   0.3  0.0   0:09.80 mount.ntfs  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3773 patrice   20   0 25.573g 5.548g  89144 S   0.3 35.5  32:40.94 python2     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 7993 patrice   20   0  345392   2596   1088 S   0.3  0.0   0:02.78 ibus-daemon \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8035 patrice   20   0   42888    480     44 S   0.3  0.0   0:00.05 dbus-daemon \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8038 patrice   20   0  206956    684     52 S   0.3  0.0   0:00.14 at-spi2-re+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 8071 patrice   20   0  968144  10340   2552 S   0.3  0.1   0:00.32 unity-sett+ \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 19:36:31 up  6:48,  1 user,  load average: 0.80, 0.58, 0.42\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  3.1 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.5 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 96.4 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383700 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  1096752 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 14744328 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m   542620 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 15165884 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  1563200 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  1144312 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m10569 patrice   20   0 1220532 141220  46668 S   4.7  0.9   1:13.87 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10686 patrice   20   0 1258864 115980  16840 S   4.3  0.7   0:35.72 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10886 patrice   20   0 20.627g 6.292g 101544 S   2.7 40.3   0:43.27 python2     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10458 patrice   20   0 1299400 181336  66760 S   0.7  1.1   0:30.29 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m10523 patrice   20   0  618104 148920  58096 S   0.7  0.9   0:19.30 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 1191 root      20   0  316836  36880  29004 S   0.3  0.2   0:15.39 Xorg        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2458 root      20   0  399720   7832   1428 S   0.3  0.0   0:34.58 docker-con+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m11447 patrice   20   0   41928   3616   2976 R   0.3  0.0   0:00.06 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185500    596    180 S   0.0  0.0   0:01.15 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.06 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:23.19 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.04 watchdog/0  \u001b[m\u001b[m\u001b[K\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
