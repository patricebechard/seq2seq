{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 30\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DATADIR = 'data/'\n",
    "\n",
    "word2ix_src_file = 'word2ix_en_filtered.json'\n",
    "ix2word_src_file = 'ix2word_en_filtered.json'\n",
    "word2ix_tgt_file = 'word2ix_fr_filtered.json'\n",
    "ix2word_tgt_file = 'ix2word_fr_filtered.json'\n",
    "\n",
    "pairs_file = 'pairs_en_fr_filtered.json'\n",
    "\n",
    "with open(DATADIR + word2ix_src_file) as f:\n",
    "    word2ix_src = json.load(f)\n",
    "with open(DATADIR + ix2word_src_file) as f:\n",
    "    ix2word_src = json.load(f)\n",
    "with open(DATADIR + word2ix_tgt_file) as f:\n",
    "    word2ix_tgt = json.load(f)\n",
    "with open(DATADIR + ix2word_tgt_file) as f:\n",
    "    ix2word_tgt = json.load(f)\n",
    "\n",
    "with open(DATADIR + pairs_file) as f:\n",
    "    pairs = json.load(f)\n",
    "    \n",
    "source_vocab_size = len(word2ix_src)\n",
    "target_vocab_size = len(word2ix_tgt)\n",
    "\n",
    "n_pairs = len(pairs)\n",
    "np.random.shuffle(pairs)\n",
    "\n",
    "#split into three subsets (train, dev, test)\n",
    "train_pairs = pairs[:(9 * n_pairs// 10)] #90%\n",
    "dev_pairs = pairs[(9 * n_pairs // 10):(19 * n_pairs // 20)] #5%\n",
    "test_pairs = pairs[(19 * n_pairs // 20):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs_batch(update_num, mode='train'):\n",
    "    #0 is UNK, 1 is BOS, 2 is EOS, 3 is PAD\n",
    "    #bos is only used in target_in\n",
    "    # i is # of update\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = train_pairs\n",
    "    elif mode == 'dev':\n",
    "        dataset = dev_pairs\n",
    "    elif mode == 'test':\n",
    "        dataset = test_pairs\n",
    "        \n",
    "    num_pairs = len(dataset)\n",
    "    \n",
    "    index = (update_num * batch_size) % num_pairs\n",
    "    inputs_batch = []\n",
    "    targets_in_batch = []\n",
    "    targets_out_batch = []\n",
    "\n",
    "    max_src_len = 0\n",
    "    max_tgt_len = 0\n",
    "    for j in range(batch_size):\n",
    "        pair = pairs[(index + j) % num_pairs]   #modulo used so that we are always in the index range\n",
    "        \n",
    "        inputs = pair['source']\n",
    "        targets_in = pair['target']\n",
    "        targets_out = pair['target']\n",
    "        \n",
    "        # add <BOS> and <EOS> tokens\n",
    "        inputs = inputs + [int(word2ix_src['<EOS>'])]\n",
    "        targets_in = [int(word2ix_tgt['<BOS>'])] + targets_in\n",
    "        targets_out = targets_out + [int(word2ix_tgt['<EOS>'])]\n",
    "        \n",
    "        if len(inputs) > max_src_len:\n",
    "            max_src_len = len(inputs)\n",
    "        if len(targets_out) > max_tgt_len:\n",
    "            max_tgt_len = len(targets_out)\n",
    "        \n",
    "        # adding to batch\n",
    "        inputs_batch.append(inputs)\n",
    "        targets_in_batch.append(targets_in)\n",
    "        targets_out_batch.append(targets_out)\n",
    "    \n",
    "    #padding sequences to same length\n",
    "    for j in range(batch_size):\n",
    "        \n",
    "        tmp = len(inputs_batch[j])\n",
    "        inputs_batch[j] = inputs_batch[j] + (max_src_len - tmp) * [int(word2ix_src['<PAD>'])]\n",
    "        \n",
    "        tmp = len(targets_out_batch[j])\n",
    "        targets_in_batch[j] = targets_in_batch[j] + (max_tgt_len - tmp) * [int(word2ix_src['<PAD>'])]\n",
    "        targets_out_batch[j] = targets_out_batch[j] + (max_tgt_len - tmp) * [int(word2ix_src['<PAD>'])]\n",
    "        \n",
    "    \n",
    "    inputs_batch = torch.LongTensor(inputs_batch).t()\n",
    "    targets_in_batch = torch.LongTensor(targets_in_batch).t()\n",
    "    targets_out_batch = torch.LongTensor(targets_out_batch).t()\n",
    "    \n",
    "    return inputs_batch, targets_in_batch, targets_out_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, source_vocab_size, target_vocab_size, embedding_size=256, hidden_size=256,\n",
    "                 attention_size=256, num_layers=1, max_seq_len=30):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        \n",
    "        self.encoder = Encoder(input_size=source_vocab_size, \n",
    "                               embedding_size=embedding_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               num_layers=num_layers)\n",
    "        \n",
    "        self.decoder = Decoder(output_size=target_vocab_size,\n",
    "                               embedding_size=embedding_size,\n",
    "                               hidden_size=hidden_size,\n",
    "                               attention_size=attention_size,\n",
    "                               num_layers=num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_size=256, hidden_size=256,\n",
    "                 num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden0 = nn.Parameter(torch.zeros(2*num_layers, 1, hidden_size//2))\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n",
    "        self.encoder_rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size//2, \n",
    "                                  num_layers=num_layers, bidirectional=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden = self._init_hidden()\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.encoder_rnn(x, hidden)\n",
    "\n",
    "        return x, hidden\n",
    "\n",
    "    def _init_hidden(self):\n",
    "        # initial hidden state is a learned bias parameter\n",
    "        hidden = self.hidden0.clone().repeat(1, batch_size, 1)\n",
    "        if use_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_size, embedding_size=256, hidden_size=256,\n",
    "                 attention_size=256, num_layers=1):\n",
    "        \"\"\"\n",
    "        We use the original attention mechanism from Bahdanau et al. 2014\n",
    "        The layers are of this model correspond to the following notation in the original paper.\n",
    "        \n",
    "        attn_fc_prev_hid : Wa\n",
    "        attn_fc_enc_hid : Ua\n",
    "        attn_fc_context : va\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        self.num_layers=num_layers\n",
    "        \n",
    "        # attention\n",
    "        self.attn_fc_prev_hid = nn.Linear(in_features=hidden_size, \n",
    "                                          out_features=attention_size)\n",
    "        self.attn_fc_enc_hid = nn.Linear(in_features=hidden_size, \n",
    "                                         out_features=attention_size)\n",
    "        self.attn_fc_context = nn.Linear(in_features=attention_size,\n",
    "                                         out_features=1)\n",
    "    \n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)    \n",
    "        self.decoder_rnn = nn.GRU(input_size=(embedding_size + hidden_size), \n",
    "                                  hidden_size=hidden_size, \n",
    "                                  num_layers=num_layers)\n",
    "        self.clf = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, encoder_outputs):\n",
    "        \n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # attention\n",
    "        tmp1 = self.attn_fc_prev_hid(self.hidden[0])\n",
    "        tmp2 = self.attn_fc_enc_hid(encoder_outputs)\n",
    "\n",
    "        context_weights = self.attn_fc_context(F.tanh(tmp1 + tmp2))\n",
    "        context_weights = F.softmax(context_weights, 0)\n",
    "        self.attn_weights = context_weights #for attention plotting purposes\n",
    "        \n",
    "        context_weights = context_weights.permute(1, 2, 0) # (batch size x 1 x seq_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # (batch size x seq_len x 2*hidden_dim)\n",
    "\n",
    "        context_vector = torch.bmm(context_weights, encoder_outputs)\n",
    "        context_vector = context_vector.permute(1, 0, 2) # (1 x batch_size x 2*hidden_dim)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        #concatenate previously predicted word embedding and context vector\n",
    "        x = torch.cat((x, context_vector), dim=-1)\n",
    "        x, self.hidden = self.decoder_rnn(x, self.hidden)\n",
    "        x = self.clf(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_hidden(self, encoder_hidden_state):\n",
    "        \n",
    "        self.hidden = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            self.hidden = self.hidden.cuda()\n",
    "        for layer in range(self.num_layers):\n",
    "            self.hidden[layer] = torch.cat((encoder_hidden_state[2*layer],\n",
    "                                    encoder_hidden_state[2*layer + 1]), dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_updates=10000, teacher_forcing_prob=0.8, print_every=1000, \n",
    "          learning_rate=1e-4, save_model=False, beam_size=10):\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    #PAD has no weight\n",
    "    weight_mask = torch.ones(len(word2ix_tgt))\n",
    "    weight_mask[int(word2ix_tgt['<PAD>'])] = 0\n",
    "    if use_cuda:\n",
    "        weight_mask = weight_mask.cuda()\n",
    "    criterion = nn.NLLLoss(weight=weight_mask)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_buffer = []\n",
    "    bleu_tracker = []\n",
    "    loss_tracker = []\n",
    "\n",
    "    # + 1 to show the last update\n",
    "    for update in range(n_updates + 1):\n",
    "        \n",
    "        loss = 0\n",
    "        teacher_forcing = True if np.random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, targets_in, targets_out = generate_pairs_batch(update)\n",
    "        inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "        if use_cuda:\n",
    "            inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "        \n",
    "        model.decoder._init_hidden(encoder_hidden)\n",
    "        \n",
    "        predicted_sequence = torch.zeros(len(targets_in)).long()\n",
    "        if use_cuda:\n",
    "            predicted_sequence = predicted_sequence.cuda()\n",
    "\n",
    "        if teacher_forcing:\n",
    "            for i in range(len(targets_in)):\n",
    "                output = model.decoder(targets_in[i], encoder_outputs)\n",
    "\n",
    "                loss += criterion(output.view(batch_size, -1), targets_out[i])\n",
    "\n",
    "                _, output = torch.max(output, -1)\n",
    "                output = output.view(batch_size)\n",
    "\n",
    "                predicted_sequence[i] = output.data[0]\n",
    "                \n",
    "        else:\n",
    "            # beam search\n",
    "            # feeding BOS tokens\n",
    "            output = Variable(torch.ones(batch_size).long())\n",
    "            beam_best_seq = torch.zeros(len(targets_in), batch_size, beam_size).long()\n",
    "            beam_best_scores = torch.zeros(batch_size, beam_size)\n",
    "            beam_seq_buffer = torch.zeros(len(targets_in), batch_size, beam_size*beam_size).long()\n",
    "            beam_scores_buffer = torch.zeros(batch_size, beam_size*beam_size)\n",
    "            if use_cuda:\n",
    "                output = output.cuda()\n",
    "                beam_best_seq = beam_best_seq.cuda()\n",
    "                beam_best_scores = beam_best_scores.cuda()\n",
    "                beam_seq_buffer = beam_seq_buffer.cuda()\n",
    "                beam_scores_buffer = beam_scores_buffer.cuda()\n",
    "            for i in range(len(targets_in)):\n",
    "                if i == 0:\n",
    "                    output = model.decoder(output, encoder_outputs)\n",
    "                    top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                    beam_best_scores = top_vals[0].data\n",
    "                    beam_best_seq[i] = top_ix.data\n",
    "                else:\n",
    "                    for j in range(beam_size):\n",
    "                        output = Variable(beam_best_seq[i-1,:,j])\n",
    "                        if use_cuda:\n",
    "                            output = output.cuda()\n",
    "                        output = model.decoder(output, encoder_outputs)\n",
    "                        \n",
    "                        top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                        top_vals = beam_best_scores[:,j].unsqueeze(-1) + top_vals.data\n",
    "                        \n",
    "                        #building buffers\n",
    "                        beam_scores_buffer[:,j*beam_size:(j+1)*beam_size] = top_vals\n",
    "                \n",
    "                        beam_seq_buffer[:i,:,j*beam_size:(j+1)*beam_size] = beam_best_seq[:i,:,j:j+1].repeat(1, 1, beam_size)\n",
    "                        beam_seq_buffer[i,:,j*beam_size:(j+1)*beam_size] = top_ix.data\n",
    "\n",
    "                    # keeping best beams from buffer\n",
    "                    top_vals, top_ix = torch.topk(beam_scores_buffer, beam_size)\n",
    "                    \n",
    "                    # updating best sequences and best scores\n",
    "                    beam_best_scores = top_vals\n",
    "                    \n",
    "                    \n",
    "                    for k in range(batch_size):\n",
    "                        for j in range(beam_size):\n",
    "                            ix = top_ix[k,j]\n",
    "                            beam_best_seq[:,k,j] = beam_seq_buffer[:,k,ix]\n",
    "            \n",
    "            #re-run with best sequence\n",
    "            best_prediction = beam_best_seq[:,:,0]\n",
    "            best_prediction = Variable(best_prediction)\n",
    "            output = Variable(torch.ones(batch_size)).long()\n",
    "            if use_cuda:\n",
    "                best_prediction = best_prediction.cuda()\n",
    "                output = output.cuda()\n",
    "\n",
    "            for i in range(len(targets_in)):  \n",
    "                output = model.decoder(output, encoder_outputs) \n",
    "\n",
    "                _, predicted_word = torch.max(output, -1)\n",
    "                predicted_word = predicted_word.view(batch_size)\n",
    "                predicted_sequence[i] = predicted_word.data[0]\n",
    "\n",
    "                loss += criterion(output.view(batch_size, -1), targets_out[i])\n",
    "                \n",
    "                #using the beam search prediction\n",
    "                output = best_prediction[i]\n",
    "            \n",
    "                predicted_sequence[i] = output.data[0]\n",
    "\n",
    "        loss /= len(targets_in) # length penalty\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        loss_buffer.append(loss.data[0])\n",
    "\n",
    "        if update % print_every == 0:\n",
    "            \n",
    "            inputs = inputs[:,0]\n",
    "            targets_out = targets_out[:,0]\n",
    "\n",
    "            # convert all sequence to list (easier to read)\n",
    "            inputs = [str(inputs.data[i]) for i in range(len(inputs))]\n",
    "            predicted_sequence = [str(predicted_sequence[i]) for i in range(len(predicted_sequence))]\n",
    "            targets_out = [str(targets_out.data[i]) for i in range(len(targets_out))]\n",
    "\n",
    "            # create string of sentence\n",
    "            og_sequence = ''.join(ix2word_src[elem] + ' ' for elem in inputs if ix2word_tgt[elem] != '<PAD>')\n",
    "            pred_sequence = ''.join(ix2word_tgt[elem] + ' ' for elem in predicted_sequence if ix2word_tgt[elem] != '<PAD>')\n",
    "            target_sequence = ''.join(ix2word_tgt[elem] + ' ' for elem in targets_out if ix2word_tgt[elem] != '<PAD>')\n",
    "            \n",
    "            #mean over print_every batches of loss\n",
    "            loss_tracker.append(np.mean(loss_buffer))\n",
    "            loss_buffer = []\n",
    "            \n",
    "            #score = compute_bleu_score(model, mode='dev')\n",
    "            score = 0\n",
    "            bleu_tracker.append(score)\n",
    "            \n",
    "            print(\"Update : %d ----- Loss : %.3f ----- BLEU : %.2f\\n-----------------------------\" % (update, loss_tracker[-1], bleu_tracker[-1]))\n",
    "            print(\"Original sequence  : %s\" % og_sequence)\n",
    "            print(\"Predicted sequence : %s\" % pred_sequence)\n",
    "            print(\"Target sequence    : %s\\n\" % target_sequence)\n",
    "            \n",
    "            if save_model:\n",
    "                #saving encoder and decoder separately\n",
    "                torch.save(model.encoder.state_dict(), 'seq2seq_encoder_en_fr.pt')\n",
    "                torch.save(model.decoder.state_dict(), 'seq2seq_decoder_en_fr.pt')\n",
    "                \n",
    "                #saving loss progress\n",
    "                np.savetxt('seq2seq_en_fr_loss.txt', np.array(loss_tracker))\n",
    "                np.savetxt('seq2seq_en_fr_bleu.txt', np.array(bleu_tracker))\n",
    "    \n",
    "    return loss_tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(source_vocab_size=source_vocab_size, target_vocab_size=target_vocab_size, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.load_state_dict(torch.load('seq2seq_encoder_en_fr.pt'))\n",
    "model.decoder.load_state_dict(torch.load('seq2seq_decoder_en_fr.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update : 0 ----- Loss : 2.983 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : counter terrorism instruments or policies which do not respect fundamental rights often play into the hands of the terrorists themselves . <EOS> \n",
      "Predicted sequence : les fonds de les regions de sante ou ou ne sont pas les droits fondamentaux des des bien les droit des etats . memes . <EOS> . . . . . \n",
      "Target sequence    : les instruments ou les politiques de contre terrorisme qui ne respectent pas les droits fondamentaux font tres souvent le jeu des terroristes eux memes . <EOS> \n",
      "\n",
      "Update : 1000 ----- Loss : 3.514 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : although this clause is rarely used it could well be used very soon in finland if i am well informed . <EOS> \n",
      "Predicted sequence : en ce n est qu il est difficile . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> ce ce \n",
      "Target sequence    : bien que cette clause soit rarement utilisee elle pourrait l etre tres bientot si mes informations sont bonnes dans le cas de la finlande . <EOS> \n",
      "\n",
      "Update : 2000 ----- Loss : 3.460 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : a principles based threats and safeguards approach will lead to a much more effective and robust eu regime . <EOS> \n",
      "Predicted sequence : une serie de la lutte contre une politique de l ue . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : une approche par risques et mesures de sauvegarde basee sur des principes conduira a un regime communautaire bien plus efficace et solide . <EOS> \n",
      "\n",
      "Update : 3000 ----- Loss : 3.394 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : thank you very much mr president . <EOS> \n",
      "Predicted sequence : merci beaucoup monsieur le president . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : je vous remercie monsieur le president . <EOS> \n",
      "\n",
      "Update : 4000 ----- Loss : 3.393 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we must get this through it is a really crucial point . <EOS> \n",
      "Predicted sequence : nous est la que nous devons un un est un probleme important . <EOS> . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : c est ce que nous devons imposer c est un point decisif ! <EOS> \n",
      "\n",
      "Update : 5000 ----- Loss : 3.331 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this should be achievable without infringing on the autonomy that member states have in running their own vocational education and training systems . <EOS> \n",
      "Predicted sequence : cela devrait etre mis en uvre les etats membres et d emploi . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : cela devrait etre realisable sans porter atteinte a l autonomie dont disposent les etats membres pour la gestion de leurs propres systemes d enseignement et de formation professionnels . <EOS> \n",
      "\n",
      "Update : 6000 ----- Loss : 3.282 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president commissioner ladies and gentlemen the miracle of bonn the kyoto baby learns to walk . <EOS> \n",
      "Predicted sequence : monsieur le president monsieur le nombre de l <UNK> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : monsieur le president madame la commissaire chers collegues un miracle s est produit a bonn l enfant de kyoto apprend a marcher . <EOS> \n",
      "\n",
      "Update : 7000 ----- Loss : 3.262 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : if parent and subsidiary companies simply provide groundhandling services for each other then we must seriously ask ourselves whether competition is genuinely being ensured ! <EOS> \n",
      "Predicted sequence : si les femme de peut plus les il la entreprises les peut egalement les concentrer des vie des l si nous situation nous la si a <EOS> a a ! ! \n",
      "Target sequence    : quand une societe ne sous traite qu a ses filiales on doit serieusement se poser la question de savoir si la concurrence est reellement assuree ! <EOS> \n",
      "\n",
      "Update : 8000 ----- Loss : 3.261 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i would like to thank them because we have really achieved a great deal . <EOS> \n",
      "Predicted sequence : je voudrais remercier remercier dire parce que nous avons fait beaucoup un bon travail . <EOS> . a . . . . . . . . . . . \n",
      "Target sequence    : je voudrais les en remercier parce que nous avons vraiment fait du bon travail . <EOS> \n",
      "\n",
      "Update : 9000 ----- Loss : 3.205 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : that said i would like to thank mrs saifi for her excellent report and i welcome the draft resolution . <EOS> \n",
      "Predicted sequence : je me dit je remercie a feliciter mme van pour son excellent rapport et je felicite felicite du vote de resolution . <EOS> . . . . . . . . \n",
      "Target sequence    : ceci etant dit je tiens a remercier mme saifi pour son excellent rapport et je me felicite du projet de resolution . <EOS> \n",
      "\n",
      "Update : 10000 ----- Loss : 3.217 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we should spend money on offshore projects in the north sea and the baltic . <EOS> \n",
      "Predicted sequence : nous devrions des mesures sur la mer . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : nous devrions consacrer de l argent a des projets offshore en mer du nord et en mer baltique . <EOS> \n",
      "\n",
      "Update : 11000 ----- Loss : 3.129 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the practice of preparing lists of writers which should not be published reminds one of times we all believed were over . <EOS> \n",
      "Predicted sequence : la pratique des est a ete des nature de comptes qui doit pas un un par un autres nous nous avons tous les . <EOS> . . . . . \n",
      "Target sequence    : la pratique qui consiste a dresser la liste des ecrivains ne devant pas etre publies evoque des temps que nous pensions tous revolus . <EOS> \n",
      "\n",
      "Update : 12000 ----- Loss : 3.171 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they are fully committed to day to day political life and perfect their military formations in the process . <EOS> \n",
      "Predicted sequence : ils sont en effet de la vie des processus . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : en effet tant le hamas le mouvement terroriste islamiste palestinien que le hezbollah son allie strategique libanais mangent pour l instant a tous les <UNK> . <EOS> \n",
      "\n",
      "Update : 13000 ----- Loss : 3.103 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they have no elected governments and almost all have no law making elected parliament . <EOS> \n",
      "Predicted sequence : ils ont ete pas les gouvernements . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : elles ne disposent d aucun gouvernement elu et presque aucune ne dispose d un parlement legislateur elu . <EOS> \n",
      "\n",
      "Update : 14000 ----- Loss : 3.057 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : lv madam president ladies and gentlemen we all know that drug taking is prohibited in sport . <EOS> \n",
      "Predicted sequence : madame madame la presidente mesdames et messieurs nous savons tous que les fait est en de le sport . <EOS> . . . . . . . . . . \n",
      "Target sequence    : lv madame la presidente mesdames et messieurs nous savons tous que le dopage est interdit dans le sport . <EOS> \n",
      "\n",
      "Update : 15000 ----- Loss : 3.088 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president commissioner honourable members mr bowis thank you very much for this productive debate . <EOS> \n",
      "Predicted sequence : monsieur le president monsieur le commissaire chers collegues monsieur le je vous remercie tres pour ce debat sur . <EOS> . . . . . . . . . . . \n",
      "Target sequence    : monsieur le president monsieur le commissaire chers deputes monsieur bowis je vous remercie infiniment pour ce debat productif . <EOS> \n",
      "\n",
      "Update : 16000 ----- Loss : 3.055 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they frequently go unpunished since the eu has different legal and penal systems . <EOS> \n",
      "Predicted sequence : ils ont fait que l ue ont besoin . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : ils restent souvent impunis parce que l ue comprend systemes juridiques et penaux differents . <EOS> \n",
      "\n",
      "Update : 17000 ----- Loss : 2.997 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : many thanks . <EOS> \n",
      "Predicted sequence : merci . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : je vous remercie mille fois . <EOS> \n",
      "\n",
      "Update : 18000 ----- Loss : 2.930 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : some members of my group reject the report because they believe that this is not a european issue . <EOS> \n",
      "Predicted sequence : certains deputes de mon groupe le le rapport parce il ne que ce n est pas une probleme europeen . <EOS> . . . . . . . . . . \n",
      "Target sequence    : certains membres de mon groupe rejettent ce rapport car ils pensent que ce n est pas un theme europeen . <EOS> \n",
      "\n",
      "Update : 19000 ----- Loss : 2.966 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : in its accession treaty it was conceded that finland could maintain its ban on <UNK> and <UNK> until . <EOS> \n",
      "Predicted sequence : dans son adhesion a la commission son <UNK> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : dans son traite d adhesion la finlande a ete autorisee a conserver son interdiction de la <UNK> et de la <UNK> jusqu en . <EOS> \n",
      "\n",
      "Update : 20000 ----- Loss : 2.949 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : as other members have already said since the eu decided to phase out single hull tankers this issue has become more important . <EOS> \n",
      "Predicted sequence : comme des autres deputes ont ont deja dit depuis l ue a decide de la une un difficultes de ce echelle . situation a ete . plus . <EOS> . . \n",
      "Target sequence    : comme d autres deputes l ont deja signale puisque l ue a decide de supprimer progressivement les petroliers a simple coque la question a gagne en importance . <EOS> \n",
      "\n",
      "Update : 21000 ----- Loss : 2.862 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : for a start why if there is to be cooperation with the mediterranean for the thing is called euromed then why not with russia and with other states ? <EOS> \n",
      "Predicted sequence : pour un il cooperation avec la mediterranee est commissaire est est t raison pourquoi pour pourquoi avec la russie ? d autres etats ? <EOS> ? ? ? ? ? ? \n",
      "Target sequence    : premierement pourquoi une cooperation avec la mediterranee le theme s appelle en effet euromed et pas avec la russie ou d autres etats ? <EOS> \n",
      "\n",
      "Update : 22000 ----- Loss : 2.916 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr topolanek the proposed measures are excellent . <EOS> \n",
      "Predicted sequence : m . les amendements . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : monsieur topolanek les mesures proposees sont excellentes . <EOS> \n",
      "\n",
      "Update : 23000 ----- Loss : 2.859 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : these must be created with the agreement of the countries involved otherwise the constitutions of some member states would certainly be infringed . <EOS> \n",
      "Predicted sequence : ces ce ces doivent etre avec avec l accord des pays qui tout doute les ont les des resultats des certains . les pays membres . <EOS> . . . . \n",
      "Target sequence    : en effet ils doivent etre crees avec l accord des pays impliques sans quoi ils poseraient certainement des problemes de constitutionnalite dans certains etats membres . <EOS> \n",
      "\n",
      "Update : 24000 ----- Loss : 2.856 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : refrigeration permits this . <EOS> \n",
      "Predicted sequence : les demande . fait . <EOS> . a . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : la refrigeration le permet . <EOS> \n",
      "\n",
      "Update : 25000 ----- Loss : 2.889 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : relations with burma went through an extremely difficult period during the last meeting we had with the asean group in manila in the philippines . <EOS> \n",
      "Predicted sequence : les relations avec la birmanie ont ete une periode extremement difficile pendant la derniere reunion nous nous avons discute avec le groupe de dans l dans etats . <EOS> . au \n",
      "Target sequence    : les relations avec la birmanie ont connu une situation exceptionnellement difficile durant la derniere reunion que nous avons eue avec le groupe asean a manille aux philippines . <EOS> \n",
      "\n",
      "Update : 26000 ----- Loss : 2.808 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this has since been done and we are grateful for this . <EOS> \n",
      "Predicted sequence : c nous et derniers ont ete faites et . nous le avons avons . . <EOS> . . . . . . . . . . . . . \n",
      "Target sequence    : entre temps ces mesures ont ete effectivement prises et nous lui en sommes reconnaissants . <EOS> \n",
      "\n",
      "Update : 27000 ----- Loss : 2.798 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i think it would be helpful to have an answer from you on this issue . <EOS> \n",
      "Predicted sequence : je pense qu il serait utile de nous avez donner de reponse . cette sujet . <EOS> . a a a . . . . . . . . . . \n",
      "Target sequence    : je crois qu il serait utile que vous nous rappeliez votre position sur ce point . <EOS> \n",
      "\n",
      "Update : 28000 ----- Loss : 2.808 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we should be pleased that you lost for europe was the winner . <EOS> \n",
      "Predicted sequence : nous devrions etre montrer que vous europe pour l est le <UNK> . le ete . <EOS> . . . . . . . . . . . . . . \n",
      "Target sequence    : nous devrions nous rejouir de votre defaite car c est l europe qui a gagne . <EOS> \n",
      "\n",
      "Update : 29000 ----- Loss : 2.789 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : in this respect i would like to congratulate you on the resolution you have just adopted on roma integration . <EOS> \n",
      "Predicted sequence : a cet accord sur la resolution vous . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : a cet egard permettez moi de vous feliciter pour la resolution que vous venez d adopter au sujet de l integration des roms . <EOS> \n",
      "\n",
      "Update : 30000 ----- Loss : 2.792 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : therefore i support the call to cancel haiti s international debt . <EOS> \n",
      "Predicted sequence : par consequent mon soutien de la dette internationale . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : c est pourquoi je suis favorable a l appel a l annulation de la dette exterieure d haiti . <EOS> \n",
      "\n",
      "Update : 31000 ----- Loss : 2.741 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : they are victims because they have had the misfortune to be born in a beleaguered country . they are victims because they are desperate and are looking for compassion . <EOS> \n",
      "Predicted sequence : ils sont des victimes parce ils ont ete le possibilite d devenir comme un pays d cas et personnes et ils sont <UNK> et sont . leur qualite . <EOS> . \n",
      "Target sequence    : ce sont des victimes car ils ont eu la malchance de naitre dans un pays de souffrance des victimes car ils sont desesperes et cherchent de la compassion . <EOS> \n",
      "\n",
      "Update : 32000 ----- Loss : 2.749 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : any further delay would rightly be regarded as political . <EOS> \n",
      "Predicted sequence : il convient d abord . <EOS> . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : tout nouveau retard serait a juste titre considere comme d inspiration politique . <EOS> \n",
      "\n",
      "Update : 33000 ----- Loss : 2.666 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : why are we using public money to support people to grow potatoes to make into starch that we cannot use in the eu ? <EOS> \n",
      "Predicted sequence : pourquoi ne nous europeens argent public a soutenir les de reduire de la dans a la violence que l a nous ne pouvons pas utiliser dans l ? <EOS> ? ? \n",
      "Target sequence    : pourquoi depensons nous l argent public pour aider producteurs de pommes de terre destinees a la fabrication de fecule que nous ne pouvons pas utiliser en europe ? <EOS> \n",
      "\n",
      "Update : 34000 ----- Loss : 2.668 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we are therefore suggesting alternative options . <EOS> \n",
      "Predicted sequence : nous sommes donc des autres solutions alternatives <EOS> . . . . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : nous proposons donc d autres pistes . <EOS> \n",
      "\n",
      "Update : 35000 ----- Loss : 2.703 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : only on this basis will it be possible to determine what changes need to be made and to introduce them . <EOS> \n",
      "Predicted sequence : seuls cette mesure est necessaire et d autres . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> seule seule \n",
      "Target sequence    : ce n est que de cette facon que l on pourra definir les changements devant eventuellement etre apportes et les traduire dans les faits . <EOS> \n",
      "\n",
      "Update : 36000 ----- Loss : 2.667 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we are mainstreaming the environment in everything we do . <EOS> \n",
      "Predicted sequence : nous sommes l environnement dans tout ce que nous faisons . <EOS> . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : nous integrons l environnement dans tout ce que nous faisons . <EOS> \n",
      "\n",
      "Update : 37000 ----- Loss : 2.613 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : jokes aside i recognise the exhaustive manner with which the report encompasses the general regulations governing the energy sector . <EOS> \n",
      "Predicted sequence : la a l de reconnais le le rapport de le ce generale les regles generales sur le secteur de l energie . <EOS> . . . . . . . . \n",
      "Target sequence    : blague a part je reconnais que le rapport reprend de maniere exhaustive les reglements generaux regissant le secteur de l energie . <EOS> \n",
      "\n",
      "Update : 38000 ----- Loss : 2.620 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president mr whitehead spoke of the additives survivors network . <EOS> \n",
      "Predicted sequence : monsieur le president m . blair . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : monsieur le president m . whitehead a parle du <UNK> <UNK> network . <EOS> \n",
      "\n",
      "Update : 39000 ----- Loss : 2.649 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the text we have adopted also provides a right to days paternity leave more than the days granted at the moment in france . <EOS> \n",
      "Predicted sequence : le texte nous nous un un droit de bruxelles jour de retard de plus que que les jours en a la italie en france . <EOS> . a a . . \n",
      "Target sequence    : le texte adopte prevoit aussi un droit a un conge de paternite de jours plus que les jours accordes pour l instant en france . <EOS> \n",
      "\n",
      "Update : 40000 ----- Loss : 2.582 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i must say i find it a bit rich for the prime minister of belgium to come along here and tell other nation states what they should do . <EOS> \n",
      "Predicted sequence : je dois dire pour moi le ministre et autres etats membres . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : pour tout dire je trouve un peu fort que le premier ministre belge se presente a nous pour dire a vingt quatre etats nations ce qu ils doivent faire . <EOS> \n",
      "\n",
      "Update : 41000 ----- Loss : 2.625 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the european union has reacted adequately and coherently . <EOS> \n",
      "Predicted sequence : l union europeenne a fait a une est est . la la responsable . <EOS> . a a . . . . . . . . . . . . . \n",
      "Target sequence    : l union europeenne a reagi comme il le fallait et de facon coherente . <EOS> \n",
      "\n",
      "Update : 42000 ----- Loss : 2.587 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i actually believe that from the humanitarian point of view the problem is one of coordination . <EOS> \n",
      "Predicted sequence : je pense qu il s agit de la coordination . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : je crois d ailleurs que d un point de vue humanitaire il s agit d un probleme de coordination . <EOS> \n",
      "\n",
      "Update : 43000 ----- Loss : 2.576 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this situation is unacceptable . <EOS> \n",
      "Predicted sequence : cette est inacceptable . <EOS> . . . a a a a a a a a a a a a a a a a a a a a a \n",
      "Target sequence    : cela est inacceptable . <EOS> \n",
      "\n",
      "Update : 44000 ----- Loss : 2.594 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we shall vote in favour of it . <EOS> \n",
      "Predicted sequence : nous voterons le vote . faveur faveur . <EOS> . a a a a a a a a a a a a a a a a a a a a a \n",
      "Target sequence    : nous soutenons le vote en sa faveur . <EOS> \n",
      "\n",
      "Update : 45000 ----- Loss : 2.567 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : by abolishing the death penalty we will strengthen human dignity and make progress on human rights issues . <EOS> \n",
      "Predicted sequence : en refus la la peine de nous la au niveau des sur questions de l homme . <EOS> . a . . . . . . . . . . . \n",
      "Target sequence    : son abolition renforce la dignite humaine et aide au developpement progressif des droits de l homme . <EOS> \n",
      "\n",
      "Update : 46000 ----- Loss : 2.525 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : mr president i welcome this debate on the budget today . <EOS> \n",
      "Predicted sequence : monsieur monsieur le president je me felicite de ce debat ait ce debat sur le budget . hui . <EOS> . . . . . . . . . . . \n",
      "Target sequence    : en monsieur le president je me rejouis que l on tienne ce debat sur le budget aujourd hui . <EOS> \n",
      "\n",
      "Update : 47000 ----- Loss : 2.568 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : may i depart from normal practice by asking you to pay greater attention to the allocated time slots . <EOS> \n",
      "Predicted sequence : puis moi de voir de pratique idee de de me de etre plus une de point de . l . <EOS> . . . . . . . . . . \n",
      "Target sequence    : permettez moi de formuler une petite remarque exceptionnellement vous pourriez peut etre tenir compte du temps imparti a chacun . <EOS> \n",
      "\n",
      "Update : 48000 ----- Loss : 2.556 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : at the same time the climate crisis is doing more damage to those living in extreme poverty . <EOS> \n",
      "Predicted sequence : parallelement ailleurs la crise climatique est a de a personnes dans vivent dans la pauvrete extreme . <EOS> . a a a . . . . . . . . . \n",
      "Target sequence    : par ailleurs la crise climatique frappe plus durement les personnes qui vivent dans une pauvrete extreme . <EOS> \n",
      "\n",
      "Update : 49000 ----- Loss : 2.566 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we must not permit the use of community funds to finance something that is punishable in these member states . <EOS> \n",
      "Predicted sequence : nous ne devons pas permettre l l fonds communautaires soient un chose de ces dans ces etats membres . <EOS> . a a . . . . . . . . \n",
      "Target sequence    : nous ne devons pas permettre que des fonds communautaires financent quelque chose de sanctionne dans ces etats membres . <EOS> \n",
      "\n",
      "Update : 50000 ----- Loss : 2.596 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : this too would be unenforceable . <EOS> \n",
      "Predicted sequence : cela erreur serait serait a claire . <EOS> . . . . . . . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : cette mesure elle aussi serait inapplicable . <EOS> \n",
      "\n",
      "Update : 51000 ----- Loss : 2.541 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it is important though that sound alternative products are available . <EOS> \n",
      "Predicted sequence : il il est important que les produits d controle de sont disponibles . <EOS> . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : toutefois il est important que des produits de substitution sains soient disponibles . <EOS> \n",
      "\n",
      "Update : 52000 ----- Loss : 2.463 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : such a europe will be strong whatever the times . <EOS> \n",
      "Predicted sequence : une telle europe sera forte et que nous la heure . <EOS> . a . . . . . . . . . . . . . . . . . \n",
      "Target sequence    : une telle europe sera forte quelle que soit l epoque . <EOS> \n",
      "\n",
      "Update : 53000 ----- Loss : 2.549 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : moreover deforestation represents the third major factor of global warming . <EOS> \n",
      "Predicted sequence : en outre la deforestation est le troisieme facteur du du rechauffement mondial la planete . <EOS> . . . . . . . . . . . . . . . \n",
      "Target sequence    : en outre la deforestation est le troisieme facteur principal du rechauffement de la planete . <EOS> \n",
      "\n",
      "Update : 54000 ----- Loss : 2.494 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : amnesty international recorded one woman leaving church to find a gang shouting kill the archbishop and kill the priests <EOS> \n",
      "Predicted sequence : amnesty international a l une femme a la existence de trouver un <UNK> <UNK> <UNK> l et ile et a l les <UNK> <EOS> <EOS> <EOS> <EOS> . . . \n",
      "Target sequence    : amnesty international a enregistre une femme quittant l eglise pour rejoindre un groupe <UNK> a mort l archeveque et a mort les pretres . <EOS> \n",
      "\n",
      "Update : 55000 ----- Loss : 2.503 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it leads nations to share and interact with one another respect and better understand each other every day . <EOS> \n",
      "Predicted sequence : elle a a nations et se et un et un faire et qu un les faire chaque moins . <EOS> . . . . . . . . . . . \n",
      "Target sequence    : elle amene les peuples a partager a dialoguer a se respecter et a mieux se comprendre au quotidien . <EOS> \n",
      "\n",
      "Update : 56000 ----- Loss : 2.471 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it may well be that by focusing on that management could have avoided some of its worst mistakes . <EOS> \n",
      "Predicted sequence : il est peut bien il soit basant sur la point de moyens pourraient pu etre certains de ces erreurs erreurs . <EOS> . . . . . . . . . \n",
      "Target sequence    : il se peut qu en se concentrant sur ce point les dirigeants auraient pu eviter certaines de leurs pires erreurs . <EOS> \n",
      "\n",
      "Update : 57000 ----- Loss : 2.439 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : parliament has presented four own initiative reports in this context . firstly there is the rothley report on the settlement of claims relating to traffic accidents . <EOS> \n",
      "Predicted sequence : le parlement ont un ont ete adoptes dans rapport rapport europeen premier rothley a le procedures de par matiere avec les question du accidents . <EOS> . . . . . \n",
      "Target sequence    : quatre rapports d initiative ont ete presentes par le parlement le rapport rothley sur les trafics automobiles en relation avec la responsabilite des accidents . <EOS> \n",
      "\n",
      "Update : 58000 ----- Loss : 2.478 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : i must say that the most important responsibility of the european commission and of the european parliament is the internal responsibility to be honest to the citizens of europe . <EOS> \n",
      "Predicted sequence : je dois dire que la responsabilite la la la commission europeenne et du parlement europeen est la responsabilite interne de plus de une aux les citoyens europeens . <EOS> . . \n",
      "Target sequence    : je dois dire que la responsabilite principale de la commission europeenne et du parlement europeen est la responsabilite interne le devoir d honnetete envers les citoyens europeens . <EOS> \n",
      "\n",
      "Update : 59000 ----- Loss : 2.458 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we have spoken of other threats to which i would like to add epidemiological threats and information security for example . <EOS> \n",
      "Predicted sequence : nous avons parle des autres menaces pour je voudrais ajouter des alternatives et et a securite de informations pour exemple . <EOS> . . . . . . . . . \n",
      "Target sequence    : nous avons aborde d autres menaces auxquelles je voudrais ajouter les menaces epidemiologiques et la securite des informations par exemple . <EOS> \n",
      "\n",
      "Update : 60000 ----- Loss : 2.467 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : under these measures some community aid to haiti is suspended . <EOS> \n",
      "Predicted sequence : dans ces mesures communautaire . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : dans le cadre de ces mesures une certaine partie de l aide communautaire a haiti est suspendue . <EOS> \n",
      "\n",
      "Update : 61000 ----- Loss : 2.453 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : of course in the future we shall have work to do to restore the moral credibility of europe as a whole . <EOS> \n",
      "Predicted sequence : bien sur en l avenir nous aurons travaille travail a faire la credibilite morale de l europe dans dans ensemble . <EOS> . . a a a a a a a \n",
      "Target sequence    : bien sur a l avenir nous aurons du travail pour retablir la credibilite morale de l europe comme un tout . <EOS> \n",
      "\n",
      "Update : 62000 ----- Loss : 2.435 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : on the other hand we do recognise that georgia has financing needs and that there is an eu responsibility here . <EOS> \n",
      "Predicted sequence : d autre part a la necessite d autres europeenne . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : par ailleurs nous reconnaissons que la georgie a besoin d un financement et que l ue y a une responsabilite . <EOS> \n",
      "\n",
      "Update : 63000 ----- Loss : 2.416 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the united states is losing markets here in the european union including perhaps in the new member states that joined in . <EOS> \n",
      "Predicted sequence : les etats unis sont les marches dans l union europeenne y compris les etre dans les nouveaux etats membres qui se rejoint a . <EOS> . . . . . . \n",
      "Target sequence    : les etats unis perdent des marches dans l union europeenne y compris peut etre dans les nouveaux etats membres qui ont adhere en . <EOS> \n",
      "\n",
      "Update : 64000 ----- Loss : 2.383 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : under existing regulations information must be entered in the commercial registers of member states and published in national official <UNK> . <EOS> \n",
      "Predicted sequence : dans les base existante des informations existantes etre en dans les grandes commerciaux nombre des etats membres et publies dans les <UNK> officielles nationales . <EOS> . . . . \n",
      "Target sequence    : selon la legislation actuelle les informations doivent etre introduites dans les registres du commerce des etats membres et publiees dans les journaux officiels nationaux . <EOS> \n",
      "\n",
      "Update : 65000 ----- Loss : 2.413 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : in conclusion progress has been visible and measurable but not yet enough and we need to really continue and improve the dynamics . <EOS> \n",
      "Predicted sequence : en conclure les progres ont ete tres et nous mais pas insuffisants loin et nous devons vraiment poursuivre et ameliorer la dynamique . <EOS> . . . . et et et \n",
      "Target sequence    : pour conclure les progres ont ete visibles et mesurables mais sont encore insuffisants et nous devons vraiment poursuivre et ameliorer la dynamique . <EOS> \n",
      "\n",
      "Update : 66000 ----- Loss : 2.379 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : thanks also to my colleague mrs palacio vallelersundi for having made such an excellent job of putting together thoughts in a motion for a resolution on this strategy . <EOS> \n",
      "Predicted sequence : je de mon mon collegue mme palacio a de avoir un un excellent excellent travail de vue de propositions dans une resolution de resolution sur cette strategie . <EOS> . \n",
      "Target sequence    : merci egalement a ma collegue mme palacio vallelersundi d avoir fait un si bon travail en regroupant des reflexions dans une proposition de resolution sur cette strategie . <EOS> \n",
      "\n",
      "Update : 67000 ----- Loss : 2.413 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : if the truth be told this problem was criminally neglected for years . <EOS> \n",
      "Predicted sequence : si est la que <EOS> s dire que ce problematique etait ete ete utilisee depuis . <EOS> . a a . . . . . . . . . . . \n",
      "Target sequence    : c est regrettable ! il faut dire que cette problematique a longtemps ete <UNK> negligee . <EOS> \n",
      "\n",
      "Update : 68000 ----- Loss : 2.361 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we have before us a completely new proposal by parliament very different from that proposed by the commission and with a different outlook from the council . <EOS> \n",
      "Predicted sequence : nous avons par la yeux un nouvelle de adoptee par parlement dans clairement par la que la par commission et avec une large different du la commission du conseil . <EOS> \n",
      "Target sequence    : nous avons sous les yeux une proposition totalement neuve du parlement tres eloignee de ce que proposait la commission et avec un avis different de la part du conseil . <EOS> \n",
      "\n",
      "Update : 69000 ----- Loss : 2.358 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we have seen from johannesburg and from kyoto and elsewhere that they do not pay a jot of attention to what we say . <EOS> \n",
      "Predicted sequence : nous avons dit et kyoto et qu il soit de pas . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : les sommets de johannesbourg de kyoto et d ailleurs sont la pour temoigner du fait qu ils n accordent pas la moindre attention a ce que nous disons . <EOS> \n",
      "\n",
      "Update : 70000 ----- Loss : 2.376 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : it should also be possible in other areas to conclude negotiations as soon after that as reasonably possible . <EOS> \n",
      "Predicted sequence : il devrait egalement possible dans les negociations . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : il devrait etre egalement possible dans d autres domaines de conclure les negociations dans les plus brefs delais raisonnables apres cela . <EOS> \n",
      "\n",
      "Update : 71000 ----- Loss : 2.311 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : both systems should operate over entire river basins and take into account the interests of all the countries and regions involved . <EOS> \n",
      "Predicted sequence : les systemes systemes devraient etre dans pied ensemble de zones et et prendre en consideration les interets de tous les pays et les . . <EOS> . . . . . \n",
      "Target sequence    : les deux systemes devraient fonctionner sur l ensemble des bassins hydrographiques et prendre en compte les interets de tous les pays et regions impliques . <EOS> \n",
      "\n",
      "Update : 72000 ----- Loss : 2.395 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the country has been closed to aid workers experts and media for weeks . <EOS> \n",
      "Predicted sequence : le pays a parvenu a organisations des et medias et des medias a des semaines . <EOS> . . . . . . . . . . . . . \n",
      "Target sequence    : le pays est ferme aux secours humanitaires aux experts et aux medias depuis des semaines . <EOS> \n",
      "\n",
      "Update : 73000 ----- Loss : 2.356 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the alternative is a segregated europe with all the attendant problems of discrimination social tension and instability . <EOS> \n",
      "Predicted sequence : l alternative est tout a tous les problemes de la pauvrete . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> \n",
      "Target sequence    : l alternative serait une europe <UNK> avec tout ce que cela implique de discrimination d agitation sociale et d instabilite . <EOS> \n",
      "\n",
      "Update : 74000 ----- Loss : 2.392 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : clearly the development of renewables is linked to environmental objectives as well as issues of employment regional development and the promotion of local initiatives . <EOS> \n",
      "Predicted sequence : il developpement des energies renouvelables est lie liee aux des objectifs environnementaux ainsi que aux l emploi et developpement regional et la promotion des initiatives locales . <EOS> . . . \n",
      "Target sequence    : le developpement des energies renouvelables est clairement lie a des objectifs environnementaux ainsi qu a l emploi le developpement regional et la promotion d initiatives locales . <EOS> \n",
      "\n",
      "Update : 75000 ----- Loss : 2.315 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : we should ask ourselves what is left of the spirit of these summits . <EOS> \n",
      "Predicted sequence : nous devons nous demander ce qui est la l experience partie . en l . ces pays . <EOS> . a a . . . . . . . a a \n",
      "Target sequence    : nous devrions nous demander ce qui reste de cette grande inspiration mise a jour dans ces sommets . <EOS> \n",
      "\n",
      "Update : 76000 ----- Loss : 2.344 ----- BLEU : 0.00\n",
      "-----------------------------\n",
      "Original sequence  : the matter was referred back to the committee responsible <EOS> \n",
      "Predicted sequence : la sujet a a renvoi ? commission <EOS> <EOS> a a a a a a a a a a a a a a a a a a a a a a \n",
      "Target sequence    : le parlement decide le renvoi en commission <EOS> \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-eb3918e45dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-190-aa18ba23806a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_updates, teacher_forcing_prob, print_every, learning_rate, save_model, beam_size)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mloss_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_tracker = train(model, n_updates = 1000000, print_every=1000, save_model=True, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def show_attention(model, teacher_forcing=True, beam_size=10):\n",
    "    \n",
    "    dataset = train_pairs\n",
    "\n",
    "    inputs, targets_in, targets_out = generate_pairs_batch(np.random.randint(len(dataset)))\n",
    "    inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "    if use_cuda:\n",
    "        inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "\n",
    "    model.decoder._init_hidden(encoder_hidden)\n",
    "\n",
    "    predicted_sequences = torch.zeros(len(targets_in), batch_size).long()\n",
    "    if use_cuda:\n",
    "        predicted_sequences = predicted_sequences.cuda()\n",
    "    attention_weights = torch.zeros(len(inputs), len(targets_out))\n",
    "    \"\"\"\n",
    "    for i in range(len(targets_in)):\n",
    "        output = model.decoder(targets_in[i], encoder_outputs)\n",
    "\n",
    "        attention_weights[:,i] = model.decoder.attn_weights.data[:,0].squeeze()\n",
    "\n",
    "        _, output = torch.max(output, -1)\n",
    "        output = output.view(batch_size)\n",
    "\n",
    "        predicted_sequences[i] = output.data[0]    \n",
    "    \"\"\"\n",
    "    # beam search\n",
    "    # feeding BOS tokens\n",
    "    output = Variable(torch.ones(batch_size).long())\n",
    "    beam_best_seq = torch.zeros(len(targets_in), batch_size, beam_size).long()\n",
    "    beam_best_scores = torch.zeros(batch_size, beam_size)\n",
    "    beam_seq_buffer = torch.zeros(len(targets_in), batch_size, beam_size*beam_size).long()\n",
    "    beam_scores_buffer = torch.zeros(batch_size, beam_size*beam_size)\n",
    "    if use_cuda:\n",
    "        output = output.cuda()\n",
    "        beam_best_seq = beam_best_seq.cuda()\n",
    "        beam_best_scores = beam_best_scores.cuda()\n",
    "        beam_seq_buffer = beam_seq_buffer.cuda()\n",
    "        beam_scores_buffer = beam_scores_buffer.cuda()\n",
    "    for i in range(len(targets_in)):\n",
    "        if i == 0:\n",
    "            output = model.decoder(output, encoder_outputs)\n",
    "            top_vals, top_ix = torch.topk(output, beam_size)\n",
    "            beam_best_scores = top_vals[0].data\n",
    "            beam_best_seq[i] = top_ix.data\n",
    "        else:\n",
    "            for j in range(beam_size):\n",
    "                output = Variable(beam_best_seq[i-1,:,j])\n",
    "                if use_cuda:\n",
    "                    output = output.cuda()\n",
    "                output = model.decoder(output, encoder_outputs)\n",
    "\n",
    "                top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                top_vals = beam_best_scores[:,j].unsqueeze(-1) + top_vals.data\n",
    "\n",
    "                #building buffers\n",
    "                beam_scores_buffer[:,j*beam_size:(j+1)*beam_size] = top_vals\n",
    "\n",
    "                beam_seq_buffer[:i,:,j*beam_size:(j+1)*beam_size] = beam_best_seq[:i,:,j:j+1].repeat(1, 1, beam_size)\n",
    "                beam_seq_buffer[i,:,j*beam_size:(j+1)*beam_size] = top_ix.data\n",
    "\n",
    "            # keeping best beams from buffer\n",
    "            top_vals, top_ix = torch.topk(beam_scores_buffer, beam_size)\n",
    "\n",
    "            # updating best sequences and best scores\n",
    "            beam_best_scores = top_vals\n",
    "\n",
    "\n",
    "            for k in range(batch_size):\n",
    "                for j in range(beam_size):\n",
    "                    ix = top_ix[k,j]\n",
    "                    beam_best_seq[:,k,j] = beam_seq_buffer[:,k,ix]\n",
    "\n",
    "    #re-run with best sequence\n",
    "    best_prediction = beam_best_seq[:,:,0]\n",
    "    best_prediction = Variable(best_prediction)\n",
    "    output = Variable(torch.ones(batch_size)).long()\n",
    "    if use_cuda:\n",
    "        best_prediction = best_prediction.cuda()\n",
    "        output = output.cuda()\n",
    "\n",
    "    for i in range(len(targets_in)):  \n",
    "        output = model.decoder(output, encoder_outputs) \n",
    "\n",
    "        attention_weights[:,i] = model.decoder.attn_weights.data[:,0].squeeze()\n",
    "        output = best_prediction[i]\n",
    "        predicted_sequences[i,:] = output.data\n",
    "       \n",
    "    #preparing the inputs by removing the padding\n",
    "    attn_in = inputs.data[:,0].cpu().numpy()\n",
    "    # attn_out = targets_out.data[:,0].cpu().numpy()\n",
    "    attn_out = predicted_sequences[:,0]\n",
    "    \n",
    "    while attn_in[-1] != 2:\n",
    "        attn_in = attn_in[:-1]\n",
    "    while attn_out[-1] != 2:\n",
    "        attn_out = attn_out[:-1]\n",
    "    \n",
    "    attention_weights = attention_weights[:len(attn_in), :len(attn_out)]\n",
    "\n",
    "    attn_in_str = [ix2word_src[str(attn_in[i])] for i in range(len(attn_in))]\n",
    "    attn_out_str = [ix2word_tgt[str(attn_out[i])] for i in range(len(attn_out))]\n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))    \n",
    "    ax.matshow(attention_weights.numpy(), cmap='bone')\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + attn_out_str, rotation=90)\n",
    "    ax.set_yticklabels([''] + attn_in_str)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.savefig(\"attention.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ed364d750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_learning_curve(loss_tracker):\n",
    "    \n",
    "    plt.plot(loss_tracker)\n",
    "    plt.show()\n",
    "    \n",
    "loss_tracker_file = 'seq2seq_en_fr_loss.txt'\n",
    "loss_tracker = np.loadtxt(loss_tracker_file)\n",
    "show_learning_curve(loss_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgYAAAF1CAYAAACTYSJSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcZHV57/HPt3t6VmZhAEUJixAUARGGVRYHRE2MykWDRkVFriJxAyXo9SYu3BgVvC7xeqMmoggSEyGCy1UUxJF9GYdZAdEooGEVGGDWnunu5/5xThdFT3V196+6+pxT9X2/XvXqqlPnqedXRTP19Pmd83sUEZiZmZkB9BQ9ADMzMysPFwZmZmZW48LAzMzMalwYmJmZWY0LAzMzM6txYWBmZmY1LgzMzMysxoWBmZmZ1bgwMDMzsxoXBpNM0nMlXS1pTf74AEkfKXpcZmZm4+HCYPJ9DfifwFaAiFgFvGEqEkvqkTRvKnKZmVlncmEw+WZHxK0jtg20K5mkb0uaJ2kOsAa4Q9IH25VvRG5J+p6k55c5rltyVmmsReSs0liLyFmlsRaRs0pjbTXWhcHke0TSXkAASDoJeKCN+faNiCeBE4ErgOcAb2ljvnovBw4F3lHyuG7JWaWxFpGzSmMtImeVxlpEziqNtbXYiPBtEm/AnsDPgI3AfcD1wO5tzHc70AdcCizOt62covd6CfAK4NfAtLLGdUvOKo3Vn0/5clZprP582hvrIwaTSFIPcEhEvBTYCdgnIo6OiHvbmParwD3AHOBaSbsDT7YxHwCSdgT2i4gryAqhE8sY1y05qzTWInJWaaxF5KzSWIvIWaWxthoLnkqYVBExBHwov78hIta1M19eiDwUEbtExF9EVib+HjiunXlzbwH+Lb9/AeM/XDXVcd2Ss0pjLSJnlcZaRM4qjbWInFUaa6uxnkqY7BtwLnA2sCuwcPjWxny/LOh9rgZ2qXu8Eti1bHHdkrNKY/XnU76cVRqrP5/25aztP94dfRvnBwp3N7j9ro35prQQyXMuAE4fse1lwEFliuuWnFUaqz+f8uWs0lj9+bQvZ/1NeZBVlKS7G2yOiNhzygdjZmaV53MMJpmkmZLOknSZpO9Ker+kme3KFxHPaXBrW1Eg6TRJe+f3JekCSU9KWiXpoLLEdUvOKo3Vn0/5clZprP582pdzG+M9tODb+G5kl4h8newEwOPIVkK8tI353tro1sZ8a4C+/P6bgGXADsBLgevKEtctOas0Vn8+5ctZpbH682lfzpE3HzGYfPtHxNsjYkl+Ow3Yr435Dq27HQOcA5zQxnwDEbE1v/8q4KKIeDQifkZ2yWRZ4rolZ5XGWkTOKo21iJxVGmsROas01lZja1wYTL7bJB0x/EDS4cAv25UsIt5XdzsNWARs1658wJCkZymbHjme7BrZYbNKFNctOas01iJyVmmsReSs0liLyFmlsbYaWzNtvDtac5JWky2D3AfcKOn3+VO7Ab+awqFsIFsWuV0+Rlbo9AI/iIjbASQtBn5XorhuyVmlsRaRs0pjLSJnlcZaRM4qjbXV2BpflTBJlK04OKpo0+qHkn5I3peB7AjQvsAlEfHhduTLc04D5kbE2rptc8h+n9aXJa5bclZprEXkrNJYi8hZpbEWkbNKY201dpiPGEyS+i9+SduTrStQ//m2a1nkz9bdHwDujYj/alOuYQuB90gaPnfiduDLEfFQyeK6JWeVxlpEziqNtYicVRprETmrNNZWYwGfYzDpJH0CWAX8H+Bz+e2zTYNaEBHXkPVK6IuIG4BHJc1tVz5JRwFL84cX5TeAW/LnShHXLTmrNNYiclZprEXkrNJYi8hZpbG2Gvs0Mc7LF3wb3w24C5g+hflOy38Rfps/3hu4uo35bqbBClrAgcAtZYnrlpxVGqs/n/LlrNJY/fm0L+fIm48YTL41ZEtSTpX3AEeRd1SMiN8Az2hjvnkRsXzkxohYATQ7UjHVcd2Ss0pjLSJnlcZaRM4qjbWInFUaa6uxNS4MJt+ngeWSfirpB8O3Nubrj4gtww/yE0/aeUap8nMoRm5cSPPfp6mO65acVRprETmrNNYiclZprEXkrNJYW419yngPLfg2vhvZiR5nkK16uHj41sZ8nwH+luySyJcBlwOfbGO+d5JNXSwmq0DnAscCtzCicUeRcd2Ss0pj9edTvpxVGqs/n/bl3OZ1xrujb+P8QGHpFOfrITvP4FLgP/L7anPOVwHXAo8Cj+T3X122uG7JWaWx+vMpX84qjdWfT/ty1t+8jsEkk/R5oB/4Qf4TgIi4rbBBmZmZjZPPMZh8BwFHAJ+ijZcrSlqtrGNWw9tk56vLe0nd/fNGPHdlWeK6JWeVxlpEziqNtYicVRprETmrNNZWY+u5MJhkEXFcg9tL2pDqVcCrm9zaZe+6+y8b8dxOJYrrlpxVGmsROas01iJyVmmsReSs0lhbja3xyodNSJodERsnGDMf+Djw4nzTNcDfR8QTkzm2aNMSy+NJXZHnuiVnlcZaRM4qjbWInFUaaxE5qzTWVmNrXBg0IOlI4HyyLoW7SXoh2Rmd7x5H+DfI1jJ4ff74LcAFwGsneYzraPwfWkBExLzJzFdntqSDyI42zcrvK78169411XHdkrNKYy0iZ5XGWkTOKo21iJxVGmursTU++bABSbcAJ5F1pzoo37YmIvYfR+yKiDhwrG1VJWlJs+cj4rgyxHVLziqNtYicVRprETmrNNYiclZprK3GPu11XBhsS9ItEXG4pOV1hcHKiHjhOGJvAj4YEdfnj48CPhsRL5rkMc6LiCeVLVyxjYh4bDLzmZlZd/DJh439IZ9OCEl9ks4G7hxn7LuAf5J0j6R7gP8LnN6GMX47/7ms7vbLup9tI2lWPr1Sv203SbuUKa5bclZprEXkrNJYi8hZpbEWkbNKY201tmYiix50yw3YEfhX4CHgYeBiYOE4Y2cAJwMfAz5PdiLix5rsf1az2zhzLgQOZwpWWszz9QG/BebUbbsSOKRMcd2Ss0pj9edTvpxVGqs/n/blrL/5iEFjnwPeGxHPjIhnAO9j/GsRfJ/scsHNwH3AemBDk/2Hl608hOxowy757a+BRWMlk/QOsisffgKck//82DjHmiQitpItvfz6fAy7ATtFRNMjFVMd1y05qzTWInJWaaxF5KzSWIvIWaWxthpb/yK+bVtxLR/PtlFi1yTmvBaYW/d4LnDtOOJWAzOBFfnjfYDLpuAz2md4fMBHgDPKGNctOas0Vn8+5ctZpbH682lvbES4MBjlQ10JbF/3eCGwepyx/wK8ICHnXcCMusczgLvGEbc0/7liOB64fYo+p+uA55Jdnrl9WeO6JWeVxurPp3w5qzRWfz7tjfU6Bo19DrhJ0qX549cBnxxn7NHA2yTdTdYrYXhdgQPGiLsIuFXS5fnjE4FvjiPff0laAHwPuErSWiB58SNJO0fEg+Pc/etk6z2sjoi1E0gz1XHdkrNKYy0iZ5XGWkTOKo21iJxVGmtrsROpIrrpBuwLvDe/7TuBuN0b3cYZuwg4M78dlDDmxcAJwPQW3vePJrDvbOAJ4KUTzDGlcd2Ss0pj9edTvpxVGqs/n/bGeh0DMzMzq/FVCWZmZlbjcwwAST5sYmZmXSciNHKbC4NcsymVc845h3POOWeb7Ycd9sqmr3nffb9ml12e2/C5e+5ePWrchg1PMGfO/IbPPfrY/U1zDg0N0dPT+EDQ0NBQk8ggO09ytOfMzKwbeCrBzMzMaipZGChrOTyR/RdLmtQmRmZmZp2okoUBEz+2fSxwZGqyY489Nilu7twdkuL6+mYkxQFIo00HmJmZja2UhYGksyW9N7//BUlX5/ePk3Rxfv8fJK2QdKOknfJtr5J0s6Rlkq6UtJOk3cn6Drxf0m3K2iBPSGphMG9eWmEwffrMpDhopTBwQWFmZiUtDMiWcjwmv38wMEdSb77tWmA74MaIODDf97ThuIg4IiIOBr4DfCgi7gW+CnwhIhZFxA1T+UbMzMyqpKxXJSwDDpY0l2xZ4WXAoWSFwRlAf0T8uG7fl+b3d5V0CfAsstaTd483Yf1VB8cee2zyUQIzM7MqK2VhEBEDku4B3gbcAKwCjgP2iog7JQ3U7T7IU+/jS8BnI+JHkhYDHx9vzkaXI5qZmXWbsk4lQDZFcDbZ1MH1ZOcJ3DZGzDxg+EL/U+q2r8ufMzMzsybKXhjsDNwUEQ8Dm/JtMPpVCf8L+A9JS4E/1m3/IfCa1JMPzczMuoWbKJEtiZzyOYy18mEzzVY+bGaslQ+bab7yYTP+HTEz60SNlkQu8xEDMzMzm2I+YkB2xOBP//TgCccNDGxJzvmc5xyQFLd06Y/H3mkUmzdvSIobGNianNNHG8zMystHDMzMzKwpFwZmZmZW48LAzMzMajq2MJB0fdFjMDMzq5qOLQwi4uiix2BmZlY1HVsYSFqX/9xZ0jX54karvMCRmZnZ6ErZK2GSDF8n9ybgJxHxaWU9iWcXOCYzM7NS6+TCYNhS4OuS+oDvR8TKogdkZmZWVh07lTAsIq4DXgzcB3xT0psb7ffoo/fXbhs3rpvSMZqZmZVFJx8xEICk3YD/ioivS5oJLAIuHrnzDjs8e4qHZ2ZmVj6dXBgMn2NwLPBBSVvJ2i+/tbARmZmZlVzHFgYRMS//eRFwUcHDMTMzq4SOP8fAzMzMxs+FgZmZmdV07FTCRPX29k44ZsaM+cn59n7BfklxjzzyX8k577//N0lxTzzxSHLO9JbNbtdsZlYEHzEwMzOzGhcGZmZmVuPCwMzMzGpcGJiZmVlNxxYGkiZ+NqGZmVmXK11hIGl3SXdKukDSXZIulnS8pOvzx4dI2l7S5ZJWSrpR0v557MclXSTpeuAiST2SPiPpFkkrJJ1W8NszMzMrtbJerrgX8JcRcYekXwJvjIijJb0a+DvgD8BtEfEaSccB3wIOymOfDxwVEVvyQuDxiDhc0nTgBklXRsS9BbwnMzOz0itrYXB3RNyR378duDq/vwbYA9gN+EuAiFgiaaGk7fJ9fhARW/L7LwdeIOl1+eN5wN7ANoVB/foAs2fPY/bseZP3bszMzCqirIVBf939obrHQ2Rj3rJNxFM21N0X8L6IuGqshDvu+CcTHaOZmVnHKd05BjmN8fx1wJsBJB0LPBIR6xvs91Pg3ZKm5fvuLWnWZA7UzMysk5T1iEGMcn/48TnABZJWkh0hGK2V8vlkUw+3SRLwMHDipI7UzMysgyjCa9JLiuc977AJx02bNj0551HH/0VS3E1Lfpqc070SzMysXkRsc4S+rFMJZmZmVoCyTiVMuZQjJ7vu+vzkfLcv+2VS3Bmf+UhyzofueTAp7oqLL0/OeeedNyXFPfHEH5NzDg4OJkb6KIWZmY8YmJmZWY0LAzMzM6txYWBmZmY1LgzMzMysxoWBmZmZ1ZSmMBhnV8VD826Ky/Lte+exp0j6rqQr8n3PzbefKukLdTneIelzRb1HMzOzsitNYZDbC/jfEfE8YB/yrorAB8m6Kt4JHB0RBwMfBz5dF/tC4HXAAcAbJO0CXAK8WlJvvs+pwDem5J2YmZlVUNnWMRitq+JqYHdgAXBRfqQgePr4rx7ulyDpDmD3iLhP0tXAqyT9CpgWEbc3SvzII/fV7s+ePdfdFc3MrCuVrTBo1lWxD/gE8POIeK2k3YElo8QO8tR7+zrwt8CvgAtGS7zjjru0NnIzM7MOULbCYKyuivOA4T/tTx3PC0bErZJ2BQ4im2YwMzOzUZTtHIOxuip+BjhX0jKaj31k7CXADRHxROtDNDMz61ylOWIQEfdS9xd9RPz3UZ57Xl3Yx/LnLwQurNv/hBEvfzTw+UkespmZWccp2xGDSSVpvqS7gA0RsWTMADMzsy5XmiMG7ZBPHTxvzB3NzMwMAKW0G+40kqKnp3fsHUd44QHHJefs79+YFPf8fY9Izvm8w/ZJinvRyw5JzvnNT16cFPe7365KzvnQw/ckxa1ftzYprn/LpqQ4gKGhtBbRqXGQ1mK8lbhWY61cpLHOEbfq/L4HEbHNf9COnkowMzOziXFhYGZmZjWVLgwkPUvSJUWPw8zMrFNU+uTDiHgAeH3R4zAzM+sU4zpiIOmtklZKWi7pwrwT4tWSVki6StKf5PtdIOnLkm6S9J+SFkv6uqQ7JH2j7vXWSfq8pDV5/A759ndIujXPc6mkmXWv+0VJN+Sv+9p8++6SVuf3eyR9RtIt+bhOy7fvLOkaSbdJWiXpqMn9CM3MzDrHmIWBpH3Jeg0cGxEHAe8HvgRcEBEHAt/OHw9bEBEvAs4CfgB8LiL2BQ6QNLxI0Rzg1ojYH7gWOCff/t2IOCzP8yvg7XWvu3NEHAW8Gjivbvvw6Z9vBx6PiMOBw4B35v0U3gT8JCIWkXVgXDHWezYzM+tW45lKeAlwaUSsBYiItZJeBLwmf/5bPP2L+of5z9XAgyO6Je4BrCJrijR8bsDFwHfz+wdI+gRZF8U5wE/rXvd7ef47JT2jwThfDrxA0uvyx/OAvYGlwDck9QHfj4iV43jPZmZmXSn1HINmF2nWd0Qc2S1xtHzDr3cBcEJErJF0CrC4wetC42ZLAt4XEVdt84R0DPBK4JuSPhcR21xcPzQ0VL+/r9U1M7MOM771FcZzjsHPgddJWgiQ/7wReGP+/JuB60aJHe3btQc4Kb9/cl38dsCD+V/3JzcZU6PX/SnwbknT8nHuLWm2pN2AhyPi68D5wKKGA+rpqd1cFJiZWefRiFtjYx4xiIg7JH0SuEbSALAceB/ZX99nA3/kqRbIjToiNrq/AThM0keBh4C/yrd/FLgVeBi4BZg7jtcddj7ZVMVtyr7ZHwZOBI4FPihpK7AOeOsYb9nMzKxrFbIksqR1ETF37D2nhpdEbs5LIjfnJZHbG2vl4iOqY6vO73u5lkSuyqdmZmbWVQopDCJiXhF5zczMrDl3VySbSmh2IsZopk+fkZyzpyftgpBWDuNtt932SXF77nnA2DuNYr+DDk2K69+0JTnn/b+/JynuoQfvTop79LH7k+IANmx4IikudSoKYHBwICmu/sqdqeN/n8zaqUxTCWZmZlZCLgzMzMysxoWBmZmZ1bStMJA0X9K7JvH1FudLMQ8/Pl3Smyfr9c3MzKy9Rwy2B97d6AlJE180IFuo6MjhBxHxz42WNjYzM7N0Ey4MJJ2ctza+TdJXJO0m6deSFipzraSXAp8G9sr3Oy//i/9aSd8na6iEpMslLZW0WtI76nL8uaRlefvlq/IuiX8NvD9/vaMkfVzSWfn+SySdm4/rV8OtlSXNkvSdvL3zZZJultRwSWQzMzObYBMlSfuQLV98ZEQMSvonskZH5wJfJVvO+PaI+Jmk3wD75e2OkbQYOCjf9vv8JU+NiMclzQSWSvou0Av8C3B0RPxe0oJ8n68C6yLi8/nrvXTE8Hoj4nBJryBr4/wysiMWj0XE/pL2I1vO2czMzEYx0YvpjydrQrQ070cwE3goIv5e0uuB04EDm8TfWlcUQHYE4MT8/p+QtUl+BnDN8H4R8fg4x3ZZ/nMZsHt+/2jgH/PXuV1Sk3V2R14v7WU/zcys+0y0MBBwYUT83dM2SrPIvtgh65C4YZT42vb8CMJLgMMjol/SErJCYzjPRA23ZR5k9PfV5HVdCJiZmU30HIOrgZMk7QQgafu8rfF5wMXAx8i6HELWybBZo6T5wNq8KNgHGO4OdDNwTH5eAZKGl+tbB0x0KeUbyDs3StoX2H+C8WZmZl1lQoVBRNwJfAS4UtJK4EqyVseHAOdFxL8B/ZJOiYjHgBslrZJ0XoOX+wnQJ+l24FPATXmOR4B3ApdLWg78e77/D4HXDJ98yOgtnet9GdhR0hrg78lOekxbg9bMzKwLdHSvBEk9QF9+VGJP4CrgeRExMGI/90powr0SmnOvhHbq3H+fzMqgUa+EtG+n6pgNLJHUlz9+18iiwMzMzJ7S0YVBRKwH0v5kNTMz60IdPZUwXkVMJWSzHFOrtzetDpw5c05yzt132y8p7tm7/GlyzgU7LEwLTJymWf/4urR8wEMP3ZsYlzbtAbB27UNJcZs2pb/P9OmLweScqf+2+d9E6x7htstmZmbWnAsDMzMzq3FhYGZmZjWVLQw0juv2VMREvpmZWYVV5otT0u5558QLJa0Gzq/rzPjxuv3uzjst/pJslcY9JV2R73uNpOcW9y7MzMzKrWqXK/4p8JaIWFrXdbEHuFrSdyNiTb7fIxFxCICknwGnR8RvJR0GfIWsGZSZmZmNULXC4N6IWJrff4Ok08jew87AvsBwYfAdAElzgCOBS+umHvowMzOzhqpWGGwAkLQH8DfAwRHxpKQLeKozY20/sqmStRGxaOyXdttlMzPrZONbo6My5xjkhr+t5wHrgXWSngm8otHOEbEOuFvSSbUXkEZZ+F8jbmZmZp1kfN9zVSsMAiAiVgErgDvJ2j1fP3KfOicDb5e0Iu+yeMJUDNTMzKyKKjOVEBH3AgfUPT51lP32bBDX8IiCmZmZPV3VjhiYmZlZG7kwMDMzs5rKTCW038Q7qg0MbE3ONo6FGxtqpfPbwMCWpLitW/uTc959z+qkuMfWPpCcc+H2z0qKm7/gGUlx0/vSu2ymduicNWtucs5Nm9YnxaX+/gBEDE1pXFHcmdE6gY8YmJmZWY0LAzMzM6txYWBmZmY1HVUYSDpF0s51j++WtLDIMZmZmVVJxxQGeTOltwG71G32mUBmZmYTULrCQNLJkm6RdJukr0jqkfRlSbeO0WL5jcAhwMV57EyyNR/PkLRM0kq3XDYzM2uuVIWBpH2AvwKOzBsfDQFvAv42Ig4DXggcK2n/urBHIuKQiPhXYCnwpohYFBGb8+cfjoiDga8CH5yyN2NmZlZBZVvH4HhgEbA0b5M8E3gI+CtJ76RJi+Vco84Ql+c/lwGvadO4zczMSm58s+tlKwwEXBgRf1fbkLVYvoqxWyyPZnh1nkHK937NzMymyMi/mxsXCqWaSgCuBk6StBOApO2B3RhHi+Xck2Qtmc3MzCxBqf6Cjog7JX0EuDK/ymAL8B5gOVmL5T/QvMXyhcBXJW0EjmzwvJmZmTUhr+0NkpI+hJ6e3lZyJsW18t8rNWcr73POnAVJcfPn75ics0q9Ejb3jzUT1tgjj9yXnPOxx9L6UKxfvzY555Ytm5LiBgcHknOm/r/Syv9j/vfUqiWIiG2+GMo2lWBmZmYFcmFgZmZmNaU6x6BIKYfL99rroOR8j699KCluxoxZyTn7ps8ce6cGUqcgAPbZ54ikuJkz5yTn7JvRlxQ3sCWtjfaTTz6WFAewfv3jSXEbNz6ZnLO/f2NSXCttxoeGUtsuT/1hfU8HWKZ7fw98xMDMzMxqXBiYmZlZTVsKgyK7Gko6M++TYGZmZhPUriMGRU7OvB+YXWB+MzOzymq5MGjUDZG6dRcbPK98+zpJn5G0RtKVkg6VtETSf0p6Vb5PT77PLZJWSDot37443/dSSXdK+la+/X3As4Elkq7O4y+QtCrvrnhmq+/XzMysk7VUGIzSDfFk8iMGTZ4HmAP8LCL2J1vy+BNkTZRem98HeDvweEQcDhwGvFPS7vlzBwJnkDVU2kvSkRHxJeA+4NiIOD7fZ5eIOCAiXghc0Mr7NTMz63StXq44WjfEZs8/mD+3JSKuzO+vBjZHxJCk1cDwl//LgRdIel3+eB6wN7AVuDUiHgCQtALYA7iRp3dY/B3wHElfBH4MDOfbRv3lVJJaukTPzMysqlotDLbphggg6W3Nns9tqbs/RN4FMSJC0vC4BLwvIq4a8fqLeaprIozSOTEiHpf0QuDPgNOB15MdhdhGT48v0DAzM2v123CbboiSduOpv9gbPb9r/lyzP8mHn/sp8O7hQkHS3pLGOrGw1mFR0g5Ab0RcDnwUSF+RyMzMrAu0dMRglG6I7yU/x6BJt8Q/0PzKheHnziebIrgtn4p4GDixyf4AXwN+Iuk+4APABXnuAD6c9EbNzMy6hLsrknVX9JLIo/OSyM21siTyo4/enxSX2iER4Ikn/pgUt2nT+uScAwNbxt6pgaGhweScXhLZWtMdvwfurmhmZmZNuTAwMzOzGk8lkE0lJEZO7kDGpVr/vbLTOyaulatEpk2bnhQ3a9bcpLh583ZIigNYsOAZSXEzZqQv7pk6JfD44w8n51y37tGkuM2bNyTnTJ2+GBxMn76o2v+fZp5KMDMzs6ZcGJiZmVlNRxYGkq4vegxmZmZV1JGFQUQcXfQYzMzMqqgjCwNJ6/KfDbswmpmZWWOt9kooq/pTgw8k68D4IHBD3oXxxmKGZWZmVm4decRghFsj4oHIrssc7sJoZmZmDXRDYTBmF0YzMzPLdGphUMTKQ2ZmZpXXqYXBaMuPeVkyMzOzJjrysHpEzMt/XgNcU7f9jMIGZWZmVgGdesTAzMzMErgwMDMzsxoXBmZmZlbTkecYpJn4hQyzZm2XnK2/f2NS3NDQUHLOdOnnbEppF4iktmtuxdDgQFLc4ODW5Jyp7aV32GGX5JzzFmyfFDc0kN6O+LHHHkqKe+ihe1rI+UBS3Pr1a5Nzpv5/PZj4u5ctz5KmldipVqWxVkvjz9VHDMzMzKzGhYGZmZnVlL4wkDRf0rvqHi+W9MMix2RmZtapSl8YANsD7x6xLXnCSVJva8MxMzPrXKUrDCSdJWm1pFWSzgQ+Dewl6TZJ5+W7zW3USlnSIkm/kLRU0hWSnplvXyLpC5JuBbzIkZmZ2ShKdVWCpEXAKcChQC9wM/BmYL+IWJTvs5gGrZSBW4EvASdExKOSXg98Cnh7/vJ9EXHYVL4fMzOzqilVYQAcDVweEZsBJF0GvLjBfrdGxAP5PsOtlJ8A9geuUnaNXA9wf13Md5qnHjk74T5MZmbWScY3C1+2wmCk0b6dG7VSFrAmIo4aJWZDWiozM7NOMPJ7rhrrGFwHnChppqQ5wInA9cDcccTeBewk6QgASdMk7du+oZqZmXWeUh0xiIjlkr4JLCUrZb6Wb7tR0irgCuDHI8Py2K2STgK+JGk+2TkK/wjcgdstm5mZjYu81CRICi+J3Ez670hPT9rVoalxAL29afXujOmzkuLmzluYFAdfNmOgAAAU6UlEQVSw0067JsXtvPNeyTm9JHJzXhK5fKo01moJImKbL7+yTSWYmZlZgVwYmJmZWU2pzjEoUkqXu2nT+pLzDQ1OT4obaKGTX+rhuFamL1IP66d2ZWxFJE6ZbOnfnJzziSceSYrr7U3/3Uvt6LjwGTsl59xjx72T4nZ6ZnoXyT8+dF9S3MMP/z455+NrH0yK27DxyaS4gYEtSXFQremLiAKmUKs2fZHwb+ZoU18+YmBmZmY1LgzMzMyspiMLA0n/TdI+RY/DzMysajquMMi7J54I7Ff0WMzMzKqmlIWBpN3zzokXS7pD0iWSZkn6qKRb8s6LX63bv7574v8ATgA+k3dkfI6kMyTdLmmFpG8X9sbMzMxKrsxXJTwPODUibpb0deBdwJci4hMAki6S9MqI+FG+f617oqS9gR9GxGX54/8B7JGvjjhv6t+KmZlZNZTyiEHu9xFxc37/YuAY4CWSbs6XRz6Op08XNOueuBL4tqSTyZoumZmZWQNlLgxGCuCfgNdGxAHA+cDMuuebdU98JfB/gUXAUknbvO+hoaHazctvmplZpxkaGmRgYEvtNpoyFwa7STo8v/8mss6LAI9K2g44qUnsOmAegLKVcnaLiGuAD+fbt2ly0NPTU7sVsbiOmZlZO/X09DJt2vTabTRlPsfgLuA9ki4A1gBfARYCtwMPALfW7TvyT/x/B74m6X3AG4Bv5B0XAb4YEWnLjJmZmXW4MhcGAxHx1hHbPprfniYiXjLi8Y08/fyDYyZ/eGZmZp2nzFMJnug3MzObYqU8YhAR9wIHFD0OMzOzbiOfgQ+S/CF0lKk9ebSVk1VTOx2mdq3MYtM6M/Y1OVlpLDNmzE6Mm5WcsyfxM9q6tT8558bELombNze7qGp0qR0SITtDPUUR3xnV+56qzngjYpt/wMo8lWBmZmZTzIWBmZmZ1bgwMDMzs5quKQzyRkp3SPpW0WMxMzMrq1JeldAm7wKOj4j7ix6ImZlZWXXkEQNJZ0lanbdnPlPSV4A9gSsknVn0+MzMzMqq444YSFoEnAIcCvQCNwNvBv4MODYi1hY4PDMzs1LruMIAOBq4PCI2A0i6DHhx/py7I5mZmTXRkVMJI7gYMDMzG6dOLAyuA06UNFPSHOBE4FpcIJiZmY2p46YSImK5pG8CS8nWpfxaRKz0ssdmZmZjc68E3Cuh87hXQvNY90poxr0SmnOvhPGoznjdK8HMzMyacmFgZmZmNR13joHZVB/Ga+Uo59DQUGLOrVOec6iFw9YDg2nj7e/fmJxTidM0rRy2HhjYkpgz9fcgLS6L9ZRAc1Ua6+TyEQMzMzOrcWFgZmZmNZUsDCTNl/Su/P5iST8sekxmZmadoJKFAbA98O78vujmySAzM7NJVNWTDz8N7CnpNmArsFHSpcD+wC8j4i1Qa6j0eWAO8Ajwtoh4qKAxm5mZlV5Vjxh8GPhtRCwCPgQcCJwB7AvsJelISdOALwF/GRGHAhcAnypqwGZmZlVQ1SMGI90aEQ8ASFoB7AE8QXYE4SplS9P1APcXNkIzM7MK6JTCoH4N00Gy9yVgTUQcVcyQzMzMqqeqUwnrgLn5/dEWqr8L2EnSEQCSpknadyoGZ2ZmVlWVPGIQEY9JukHSKmATUH9CYeT7bJV0EvAlSfOBXuAfgTumfMBmZmYV4e6KuLuitSq9u2JqZ8bWOjr2JsX1JsYB9E5L6+g4LbETJFRrSeTUuNa6K6Yvp5yqWt83VRprOndXNDMzs6ZcGJiZmVlNJc8xKIvp02cmxw4MpHWbK+LwXyuH1KS02rNKh8qn9U1PigOYMWN2UtzMmXOSc86aNXfsnSYxDmDOnHlJcTNnpL9PEn+H+jdvSE755LrHkuLWr1+bFNdK98nUaYhWpi9SpxJa6iKZ2k20pc6ViTlb+Pc95bPdvHl9w+0+YmBmZmY1LgzMzMysxoWBmZmZ1XRcYSBpSd48aeT2UyR9qYgxmZmZVUVHFQYa+0y37rgw1czMLFFpCgNJZ0t6b37/C5Kuzu8fJ+liSW+QtCq/nVsXt07SZyUtB1404jVPlXSXpJsB90wwMzMbQ2kKA+A64Jj8/sHAHEm9+bZfA+cCx5K1WD5U0gn5vnOAmyLioIi4YfjFJO0MnENWLBxN1pLZzMzMmihTYbAMOFjSXLJuiTcBh5IVBmuBX0TEY5FdIPqvwIvzuEHgsgavdziwJI8ZAL7T7jdgZmZWVoODA2zd2l+7jaY0hUH+5X0P8DbgBrIjCMcBe+XbR1utZFOMvrJD+io5ZmZmHaS3dxp9fTNqt9GUpjDIXQecDVwLXA/8NbAcWAq8WNLCfHrhjcAv8pjRvvxvyWO2l9QHvK6dAzczM+sEZSwMdiY7Z+BhspbK10bEg8CHyYqB5cAvI+L/5TEjjxYMt11+kOwcg5vz13W7ZTMzszG47TLpbZfdK2Fs7pXQnHslNOdeCc25V8I4Yt0rYVSbN69322UzMzNrzoWBmZmZ1XgqgfSphNYuevDnXj5TfxFLT0+Fplp6+5JzTm9yBnQzM1qYMpkzZ35S3OwWpkx6p6V9Rs0uHWtm48Ynk+IANm1clxTXv2VTcs6BgS1Jca1NX6Qdnm/lu7Eq36sDA1s8lWBmZmbNuTAwMzOzGhcGZmZmVtPRhcE4ui2amZlZnUp/cUq6XNJSSaslvSPfVt9t8QhJiyT9It/vCknPLHjYZmZmpTWt6AG06NSIeFzSTGCppMt4qtvi2ZKmAdcAJ0TEo5JeD3wKeHuBYzYzMyutqhcG75d0Yn7/T4C9gQGe6rb4PGB/4Cpl13f1APdP+SjNzMwKNjQ0NK7LNytbGEhaDLwEODwi+iUtAWYCm+u6LQpYExFHFTVOMzOzMsjWTXnqDILR1pWo8jkG84G1eVGwD3BEvr1+sYa7gJ0kHQEgaZqkfad4nGZmZpVR5cLgJ0CfpNvJzhu4Md9eW3IqIrYCJwHnSVpB1pnxRVM9UDMzs6qo7FRCRGwB/qLBU/NG7LcKWDwlgzIzM6u4Kh8xMDMzs0nmwsDMzMxq3F0Rd1e0IqX9DrXSXTFVaifILDato2NqHEBfakfHGbOSc86auV1S3PQWcqbasiWto2N//8bknKldJFO7MkJ6Z8ahVjo6Jv77PtXfx1u39ru7opmZmTXnwsDMzMxqOrIwkHR90WMwMzOroo4sDCLi6KLHYGZmVkUdWRhIWpf/XCxpiaRLJd0p6VtFj83MzKzMKrvA0RjqT+08ENgXeBC4QdKREXFj4zAzM7Pu1pFHDEa4NSIeyBsrrQD2KHg8ZmZmpdWpRwzq1V84O0h3vGczM7On6fi2y2OY+tVfzMzMSmxk2+WhocHG+03ReKbaaMtHeblBMzOzJrwkMl4S2YrkJZHbEQdeEnksXhK5OS+JbGZmZoYLAzMzM6vjwsDMzMxqOvWqhAQTn7OdNq0vOdvAwNbESJ+b0D5TP9+fGtvK3HtvYmxvC7/vqfP9M2fOSc653ZwFaXFzt0/OOScx5/TpaecYtPK7lzrfv3nzhuScqbGt5Ew9J6KV8xpS/30fz6WEkxn76KP3N9zuIwZmZmZW48LAzMzMaipVGEg6Q9IdE22GJOlMSTPbNS4zM7NOUanCAHgX8NKIeMsE494PzG7DeMzMzDpKZU4+lPQVYE/gCkn/CpwIzAA2AadGxG8k9QDnAX9O1hfha2TFz7OBJZIeiYjjC3kDZmZmFVCZwiAi3iXpz4Bjga3AZyNiSNLxwKeBk4DTgd2BAyIiJC2IiMclfQA4NiLWFjV+MzOzKqhMYZBTflsAXCRpb7Lr94bfx/HAV/IWy0TE4yPimhh5GaD7MJmZWefYurV/XJepVq0wGP72/gTw84h4raTdgSWtv7QLATMz61x9fTOetqbIpk3rG+5XtZMPh7+95wP35fdPrXv+KuB0Sb0AkoZXKnkSmDclIzQzM6uwqhUGw0cMPgOcK2kZT38P5wN/AFZJWg68Md/+NeAnkq6espGamZlVkNsuM9x22Usim5dEbhrnJZHH5CWR2xPrJZHbE/voo/e77bKZmZk158LAzMzMaqp2VUKptHLYx8Yy9VeJpB6WLWIqoZWcJMa2Mu04ODiQFNffvyk5Z+p4BwZTp/lg69a0w8/z5i5Mipu/4BlJcQDP3m2PpLiddt0pOeeOu+yQFLf9zmmfD8CCndKmd3acNzc55/zZaVNDvUr/W33d5s0TjnnJfvs13O4jBmZmZlbjwsDMzMxqprwwkHSBpNc22P4sSZdM9XjMzMzsKaU5xyAiHgBeX/Q4zMzMulnbjxhIequklZKWS7qQ7EL8xZJukPSfw0cPJO0uaXV+/xRJ35V0haS7JJ1X93ovk3SjpF9K+o6k2fn2cyWtkbRC0mfybTtK+g9Jt+S3I9v9fs3MzKqsrUcMJO0L/C3woohYK2kB8AVg54g4StLzgR8Al+Uh9acRvxA4kKyT4l2S/g+wGfgIcHxEbJL0IeAsSV8GToyIffK8w8sffxH4fETcKGlX4KfAvu18z2ZmZlXW7qmElwCXDrc7zlsgA3wvf3ynpNGut7k6ItYDSLqdrJ3y9mRf7Dcoe6E+4EbgCWCTpPOBHwH/L3+NlwLP11PXdm0naXZENFgKy90Vzcysc6249VZWLF065n5FnWNQvxbnaN/A9fsMkY1VwJURcfLInSUdRtZ2+XXAe/P7Ag6PiHFcmOxCwMzMOteBhx3GgYcdVnt80Ze/3HC/dp9j8HPgdZIWwtO6HdabyDfyzcBRkvbKX2+2pL0lzQEWRMRPgLOAA/L9rwTOrCWSXpjwHszMzLpGW48YRMQdkj4JXCNpAFjOtsfsx7M8WeSv94iktwH/JmlGvv0jwDrg+5Jm5vt/IP95JvBPklYCvcC1wLtbeEtmZmYdre1TCRHxLeBbTZ6fl/+8l/wv/Yi4ELiwbp8T6u7/AjiMbR3e4LUfBd6QOHQzM7Ou45UPzczMrMaFgZmZmdW4MDAzM7Oa0iyJXLyJt2hVCy0yYbCFWOt2rbRd7unpTYqbNq0vOee0adOT4qZPnzn2TqOYNSutbe7cxBbIANtv/8ykuPnz0loZz9puTlIcAIltqf/4+4eTUz74uweT4rb2p7WzBtiyJS12y5b0lt9btky8BTJAf3+DJXamIHYkHzEwMzOzGhcGZmZmVtNVhYGku4cXWzIzM7NtdVVhQMqJBGZmZl2ksMJA0lmSVktaJelMSWdLem/+3BckXZ3fP07St/L76yT9Q95a+UZJO+XbG7ZXlrRQ0k/zPF/DDRHMzMyaKqQwkLQIOAU4FHgR8A7gOuDF+S4HA3Mk9QLHkC1lDDAHuDEiDsz3Py3fPtxe+XDgJOD8fPvHgesi4gXA5cBu7XxfZmZmVVfU5YpHA5dHxGYASZeRLWm8SNJcss6Ky8gKh2OA9+Vx/RHx4/z+MrK2ytC4vfIcskLjNQAR8WNJa9v7tszMzMpp3brHWLfusTH3K8s6BiJrrXw38DbgBmAVcBywV0T8Kt+vvn3yIE+Nv2F7ZUkjzynwVIKZmXWluXMXPm2djgce+G3D/Yo6x+A64ERJM/O/7F+Tb7seOJts6uB64K/JOjIOG+2LfbT2ytcCJ+fbXgEsmMT3YGZm1nEKKQwiYjnwTWApcBPwLxGxkqw42Bm4KSIeBjbx1PkFMPpVBWcCh0haKWkNcHq+/e+BF0taDZwI/H6y34uZmVknUSQui9lJGkw5jEvqMq8AAwNbx96poW757zX1sz6pywy3sjxxamxvb/osYG9v2tLGXhJ5bFVaErlv+tTPJA8ODCXFeUnk9sQuW/ZTImKbf4S6bR0DMzMza8KFgZmZmdWU5aqESkqfDoDumRJINfWfT+q0WhGzcYODAy1E90/aOMarlemWqc7Z2tRQ2t9aqTl7WujwqsQumz096TlTO3u29N+kShejtfA+W5leHMlHDMzMzKzGhYGZmZnVuDAwMzOzGhcGZmZmVuPCwMzMzGpcGJiZmVmNL1c0MzPrAlu39jMwMPZKkC4MzMzMukBf3wz6+mbUHm/evKHhfp5KMDMzs5quKgwk/UjSzkWPw8zMrKy6aiohIl5Z9BjMzMzKrKuOGJiZmVlzLgzMzMysxoWBmZmZ1XTVOQaTz62TrYqq09K6tZxFtNsdLCBnGrfCbmfOxDbaPelfyX1905NjtxnHpL2SmZmZVV5pCgNJSyT9StJtkpZLuqTuuXdKulPSHZJulnRU3XOvymNWSFoj6bRi3oGZmVn1FTqVIKkPmBYRm/JNb4yI5SP2eRVwGnBkRKyVdBDwPUmHAo8B/wwcEhEP5K+3Rx63ICIen6r3YmZm1gkKOWIgaR9JnwV+BTx3jPF8CDg7ItYC5IXDN4H3AHOBXmD4ua0R8Zs87q8krZb0AUk7tuedmJmZdZYpKwwkzZb0NknXAf8C3A4cEBEr63a7OJ8WuE3Sefm2/YDbRrzcMmC/vFj4IXCvpG9LepPysz4i4p+BPwfmANdIukTSnw0/b2ZmZtuayqmEB4CVwNsj4tej7POmkVMJjHEKdUScJukfgZcCfwO8DDg1f+4+4B+Af5D0CuAbwFLgxOR3YWZm1sGmcirhL4H7gMskfUTSbg32afTX/B3AwSO2HUx2xAGAiLg9Ir4IvDzP89QLSodK+jLwReDfgf+Z/hbMzMyqaWBgK/39G2u30UxZYRARP4uINwLHAE8C35d05YgCoVFh8L+B8yQtBJB0IHAK8GVJcyQtrtv3IOCefL+XSVoJfAL4ObBvRPxNRNw52e/NzMys7KZN62PGjNm122hUxMIjteTSIcADEXGfpCXAzsAmsgLhjxHx8ny/04EPAEPAOuCsiLhB0nbAd4A987gNwBkRsTy/euGRiPjDOMbhlYrMOo5PJ2rGCxy1M2c1Fjhat+4xosFKYIUWBmXhwsCsE432j3M0eW4sqbHlyznal1dEJH+xjRWbmrPZcxFDTb/8R3tuaGiInp5mcY1zjhXXPHaQnp7eUeNGKwwGBwfo7W1eNIxWGAwMbGXatL6Gz41WGJRmgSMzMyuDVv5OSott5Q/U1NiIoSmNg6yoSItLX2p7cHDrhGNcGJiZmVmNCwMzMzOr8TkG+BwDMzPrTj750MzMzJryVIKZmZnVuDAwMzOzGhcGZmZmVuPCwMzMzGpcGJiZmVnN/wcziNarK/UP8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc617a7410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_attention(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def compute_bleu_score(model, n_updates=100, mode='dev', beam_size=2, teacher_forcing=True):\n",
    "    \n",
    "    score = 0\n",
    "    #we do a mean over 100 updates for the BLEU score on the dev and test set\n",
    "    for update in range(n_updates):\n",
    "        \n",
    "        inputs, targets_in, targets_out = generate_pairs_batch(update, mode='dev')\n",
    "        inputs, targets_in, targets_out = Variable(inputs), Variable(targets_in), Variable(targets_out)\n",
    "        if use_cuda:\n",
    "            inputs, targets_in, targets_out = inputs.cuda(), targets_in.cuda(), targets_out.cuda()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = model.encoder(inputs)\n",
    "        \n",
    "        model.decoder._init_hidden(encoder_hidden)\n",
    "        \n",
    "        predicted_sequences = torch.zeros(batch_size, len(targets_in)).long()\n",
    "        if use_cuda:\n",
    "            predicted_sequences = predicted_sequences.cuda()\n",
    "        \n",
    "        if teacher_forcing:\n",
    "            for i in range(len(targets_in)):\n",
    "                output = model.decoder(targets_in[i], encoder_outputs)\n",
    "\n",
    "                _, output = torch.max(output, -1)\n",
    "                output = output.view(batch_size)\n",
    "\n",
    "                predicted_sequences[:,i] = output.data\n",
    "        \"\"\"\n",
    "        # beam search\n",
    "        # feeding BOS tokens\n",
    "        output = Variable(torch.ones(batch_size).long())\n",
    "        beam_best_seq = torch.zeros(len(targets_in), batch_size, beam_size).long()\n",
    "        beam_best_scores = torch.zeros(batch_size, beam_size)\n",
    "        beam_seq_buffer = torch.zeros(len(targets_in), batch_size, beam_size*beam_size).long()\n",
    "        beam_scores_buffer = torch.zeros(batch_size, beam_size*beam_size)\n",
    "        if use_cuda:\n",
    "            output = output.cuda()\n",
    "            beam_best_seq = beam_best_seq.cuda()\n",
    "            beam_best_scores = beam_best_scores.cuda()\n",
    "            beam_seq_buffer = beam_seq_buffer.cuda()\n",
    "            beam_scores_buffer = beam_scores_buffer.cuda()\n",
    "        for i in range(len(targets_in)):\n",
    "            if i == 0:\n",
    "                output = model.decoder(output, encoder_outputs)\n",
    "                top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                beam_best_scores = top_vals[0].data\n",
    "                beam_best_seq[i] = top_ix.data\n",
    "            else:\n",
    "                for j in range(beam_size):\n",
    "                    output = Variable(beam_best_seq[i-1,:,j])\n",
    "                    if use_cuda:\n",
    "                        output = output.cuda()\n",
    "                    output = model.decoder(output, encoder_outputs)\n",
    "\n",
    "                    top_vals, top_ix = torch.topk(output, beam_size)\n",
    "                    top_vals = beam_best_scores[:,j].unsqueeze(-1) + top_vals.data\n",
    "\n",
    "                    #building buffers\n",
    "                    beam_scores_buffer[:,j*beam_size:(j+1)*beam_size] = top_vals\n",
    "\n",
    "                    beam_seq_buffer[:i,:,j*beam_size:(j+1)*beam_size] = beam_best_seq[:i,:,j:j+1].repeat(1, 1, beam_size)\n",
    "                    beam_seq_buffer[i,:,j*beam_size:(j+1)*beam_size] = top_ix.data\n",
    "\n",
    "                # keeping best beams from buffer\n",
    "                top_vals, top_ix = torch.topk(beam_scores_buffer, beam_size)\n",
    "\n",
    "                # updating best sequences and best scores\n",
    "                beam_best_scores = top_vals\n",
    "\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    for j in range(beam_size):\n",
    "                        ix = top_ix[k,j]\n",
    "                        beam_best_seq[:,k,j] = beam_seq_buffer[:,k,ix]\n",
    "\n",
    "        #re-run with best sequence\n",
    "        best_prediction = beam_best_seq[:,:,0]\n",
    "        best_prediction = Variable(best_prediction)\n",
    "        output = Variable(torch.ones(batch_size)).long()\n",
    "        if use_cuda:\n",
    "            best_prediction = best_prediction.cuda()\n",
    "            output = output.cuda()\n",
    "\n",
    "        for i in range(len(targets_in)):  \n",
    "\n",
    "            output = best_prediction[i]\n",
    "\n",
    "            predicted_sequences[:,i] = output.data\n",
    "        \"\"\"  \n",
    "        for j in range(batch_size):\n",
    "            \"\"\"\n",
    "            output = ''.join(str(ix2word_tgt[str(word)]) + ' ' for word in predicted_sequences[j] if word not in [0, 1, 2, 3, int(word2ix_src['.'])])\n",
    "            reference = ''.join(str(ix2word_tgt[str(word)]) + ' ' for word in targets_out[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])])\n",
    "            \n",
    "            with open('output', 'w') as output_file:\n",
    "                output_file.write(output)\n",
    "\n",
    "            with open('reference', 'w') as reference_file:\n",
    "                reference_file.write(reference)\n",
    "\n",
    "            from os import system\n",
    "            x = system('./multi-bleu.perl reference < output')\n",
    "#             score += tmp\n",
    "            \"\"\"\n",
    "            \n",
    "            output = [str(ix2word_tgt[str(word)]) for word in predicted_sequences[j] if word not in [0, 1, 2, 3, int(word2ix_src['.'])]]\n",
    "            reference = [str(ix2word_tgt[str(word)]) for word in targets_out[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])]]\n",
    "            try:\n",
    "                tmp = sentence_bleu(reference,output)\n",
    "            except:\n",
    "                continue\n",
    "            if tmp > 0.65:\n",
    "                print('Source : ' + ''.join(str(ix2word_src[str(word)]) + \" \" for word in inputs[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])]))\n",
    "                print('Output : ' + ''.join(str(ix2word_tgt[str(word)]) + \" \" for word in predicted_sequences[j] if word not in [0, 1, 2, 3, int(word2ix_src['.'])]))\n",
    "                print('Target : ' + ''.join(str(ix2word_tgt[str(word)]) + \" \" for word in targets_out[:,j].data if word not in [0, 1, 2, 3, int(word2ix_src['.'])]))\n",
    "            \n",
    "        \n",
    "    score = score * 100 / (batch_size * n_updates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : the vote will take place tomorrow at noon \n",
      "Output : le vote aura lieu demain a heures . \n",
      "Target : le vote aura lieu demain a heures . \n",
      "Source : i hope therefore that the commission accepts these positions \n",
      "Output : j espere donc que la commission accepte ces positions . \n",
      "Target : j espere donc que la commission retiendra ces positions . \n",
      "Source : \n",
      "Output : souhaits intentions autre s autre autre a l urgence premier urgence le autres autres \n",
      "Target : et troisiemement l amendement qui reclamait un rapport annuel sur l application de l acces propose pour les autorites concernees . \n",
      "Source : the commission made a clear assessment of this issue \n",
      "Output : la commission a fait fait une point . \n",
      "Target : la commission a clairement evalue ce probleme . \n",
      "Source : mr president first of all i would like to congratulate the commissioner on his successful ban on driftnets which was long overdue \n",
      "Output : monsieur le president je voudrais tout d abord feliciter le commissaire pour son une a son l restitutions de a a ont ete ete moment . . . \n",
      "Target : monsieur le president je voudrais tout d abord feliciter le commissaire pour etre parvenu a interdire les filets derivants mesure qui aurait deja du intervenir depuis longtemps . \n",
      "Source : i would ask the house to back this idea \n",
      "Output : je voudrais demander a l assemblee de revenir cette idee . \n",
      "Target : je voudrais demander a l assemblee de soutenir cette idee . \n",
      "Source : it would melt down \n",
      "Output : cela ferait <UNK> . l . \n",
      "Target : elle serait reduite a neant . \n",
      "Source : it is absolutely essential that this right to participate should be applied widely to the parties concerned \n",
      "Output : il est absolument essentiel que ce droit a participer doit impose a aux parties concernees . \n",
      "Target : il est absolument essentiel que ce droit de participation s applique largement aux parties concernees . \n",
      "Source : i am therefore opposed to extending the established enlargement process now to just any other country \n",
      "Output : je suis donc oppose a la que le voulons a un le l autres pays d pays il soient d meme d elargissement . ils disposons tous . \n",
      "Target : je suis donc oppose a ce que nous etendions a present a d autres pays quels qu ils soient le processus d elargissement dont nous avons decide . \n",
      "Source : i hope that will be supported \n",
      "Output : j espere que cela amendement sera soutenu . \n",
      "Target : j espere que cet amendement sera soutenu . \n",
      "Source : we are therefore calling on the commission to prepare a new energy efficiency action plan action to take account of the needs of vulnerable consumers \n",
      "Output : nous demandons donc a la commission de il prepare une nouvel plan d action energetique l efficacite des d doit compte des besoins des consommateurs vulnerables . \n",
      "Target : nous demandons donc a la commission qu elle elabore un nouveau plan d action sur l efficacite energetique qui tienne compte des besoins des consommateurs vulnerables . \n",
      "Source : mr santos was the first person to mention that \n",
      "Output : m . chichester a ete le premier pas la expression . \n",
      "Target : m . santos a ete le premier a l evoquer . \n",
      "Source : energy efficiency and the use of renewable sources of energy must be stepped up to meet at least the ambitious targets of the union \n",
      "Output : l efficacite energetique et l utilisation des energies renouvelables d etre mis de a a moins de niveau des il les objectifs ambitieux de l union . . \n",
      "Target : l efficacite energetique et l utilisation d energies renouvelables doivent etre accrues et amenees au moins au niveau qu exigent les objectifs ambitieux de l union europeenne . \n",
      "Source : mr brown says there will be no more institutional debate \n",
      "Output : monsieur le dit qu il n y aura pas de debat debat institutionnel . \n",
      "Target : monsieur brown indique qu il n y aura plus d autre debat institutionnel . \n",
      "Source : mr buttiglione was the scapegoat \n",
      "Output : m . buttiglione etait le ideologie . a . television . \n",
      "Target : m . buttiglione etait l arbre qui cachait la foret . \n",
      "Source : as of today states have signed the statute and have ratified it \n",
      "Output : comme a present les unis signe le statut et l ont ratifie . \n",
      "Target : jusqu a present etats ont signe le statut et l ont ratifie . \n",
      "Source : an issue was raised about the cost \n",
      "Output : une s ete ete souleve de l des \n",
      "Target : il a egalement ete question de couts . \n",
      "Source : there is no maximum limit established for residues and de facto the use of these substances has been prohibited since the st january \n",
      "Output : il n y a pas de limite maximale de pour les marchandises et de produits a utilises l usage l stockage du . la periode . . apres . \n",
      "Target : il n y a pas de limite maximale fixee pour les residus et ces substances sont de fait depuis le ler janvier de cette annee interdites d utilisation . \n",
      "Source : he had nothing to say on the subject \n",
      "Output : il n avait rien a dire sur propos sujet . \n",
      "Target : il n avait rien a dire a ce sujet . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score : 0.2428\n"
     ]
    }
   ],
   "source": [
    "compute_bleu_score(model, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 24 16:10:37 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 27%   39C    P2    32W / 120W |    714MiB /  6069MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1290      G   /usr/lib/xorg/Xorg                           200MiB |\n",
      "|    0      3171      G   compiz                                        41MiB |\n",
      "|    0      5456      G   ...24328740,131072 --enable-crash-reporter    40MiB |\n",
      "|    0      5669      C   /usr/bin/python2                             427MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 15:36:05 up 4 min,  1 user,  load average: 1.62, 1.45, 0.66\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 340 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 339 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 28.7 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  4.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m 21.2 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 42.4 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  1.8 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  1.7 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 16383692 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  6748444 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m  6467688 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  3167560 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 16729084 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m  9405160 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3974 patrice   20   0 1242620 198268  77952 S  12.5  1.2   0:30.56 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3285 patrice   20   0 1023196 114152  68972 S   6.2  0.7   0:02.50 compiz      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3937 patrice   20   0  626056 171800  95372 S   6.2  1.0   0:09.11 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4084 patrice   20   0 1276816 203504  59420 S   6.2  1.2   0:06.55 chrome      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185576   6192   3980 S   0.0  0.0   0:01.01 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    3 root      20   0       0      0      0 S   0.0  0.0   0:00.08 kworker/0:0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    5 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kworker/u8+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.39 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
